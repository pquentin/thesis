% vim: set spelllang=fr:

\setchapterpreamble[ur][.7\textwidth]{%
  \dictum[Robin Hobb, \textit{La Voie royale}]{%
  Un jour, alors que je venais de connaître Burrich, il m'avait ordonné de défaire le harnais d'un équipage de chevaux. [...] Quand Burrich revint voir ce qui me prenait tant de temps, il demeura muet de stupéfaction mais ne put me reprocher de n'avoir pas obéi à son ordre. Quant à moi, j'étais effaré du nombre de pièces qui entraient dans la composition d'un objet apparemment d'une seule pièce quand je m'y étais attaqué. [...] Tous ces sont pour faire un mot, tous ces mots pour former une pensée ! Le langage tombait en morceaux entre mes mains. Jamais je n'y avais réfléchi.}}

\chapter{État de l'art} 
\label{ch:etatdelart} 

La représentation du sens des mots (section~\ref{sec:mots}) occupe une place
importante dans nos travaux, en particulier pour la traduction de la ressource
WordNet (Chapitre~\ref{ch:wonef}). La traduction de ressources lexicales
(section~\ref{sec:translation}) est un moyen de faire profiter une langue cible
d'une ressource existante dans une autre langue, comme nous le faisons dans la
partie~\ref{part:translation}. Enfin, l'annotation en rôles sémantiques
(section~\ref{sec:srl}) sera, elle, surtout utile pour la
partie~\ref{part:srl}.

\section{Représentation des mots}
\label{sec:mots}

Nous abordons certains aspects du sens des mots à travers les dictionnaires et
différentes ressources lexicales. Nous présentons ensuite les modèles de langue
qui sont une manière directe de représenter les mots, leur utilisation, et donc
leur sens, le tout à partir d'un corpus brut.

\subsection{Représentation du sens des mots}
\label{subsec:sens_mots}

«~La lexicographie est la science qui consiste à recenser les mots, les
classer, les définir et les illustrer, par des exemples ou des expressions,
pour rendre compte de l'ensemble de leurs significations et de leurs acceptions
au sein d'une langue, afin de constituer un dictionnaire~»
\citep{wikipedia2014lexicographie}. La lexicographie est donc un socle sur
lequel le Traitement Automatique des Langues peut s'appuyer pour représenter le
sens des mots.

Pour pouvoir identifier les différents sens d'un mot, les lexicographes
n'opèrent pas par intuition linguistique \citep{kilgarriff1997don}. Ils
commencent par établir un corpus équilibré et de taille assez importante pour
représenter la langue étudiée. Ce corpus peut par exemple être constitué de
textes de journaux, de fiction, ou encore de blogs, le tout étant supposé être
représentatif de ce qu'une personne lambda lit durant sa vie. Pour un mot
donné, le lexicographe examine ses différents usages dans ce corpus dans le but
de séparer ces différents usages en sens. Certains sens, jugés trop peu
fréquents, sont laissés de côté. Le lexicographe étudie ensuite la séparation
obtenue pour établir des critères objectifs distinguant les différents sens du
mot étudié. Une phase d'ajustement de la séparation suit pour vérifier que les
critères ont été correctement appliqués, ce qui peut amener à raffiner ces
critères. Une fois les critères définitifs établis, la définition peut être
rédigée, les occurrences étudiées pouvant servir d'exemples.  L'avantage
principal est que le processus lexicographique est basé sur des données réelles
et non pas sur des intuitions linguistiques.

% TODO exemple

Ainsi, les sens ne sont pas définis en tant que tels, mais sont avant tout des
occurrences dans un contexte donné. C'est une façon de comprendre la citation
de \citep{firth1957synopsys} : \emph{You shall know a word by the company it
keeps}\footnote{Vous devriez connaître un mot par ce qui l'accompagne.}. En
effet, selon \citep{kilgarriff1997don}, un ensemble de sens n'est défini que
par rapport à un corpus, et il est illusoire de vouloir définir un dictionnaire
parfait pour tous les sens possibles d'un mot.  Néanmoins, il n'est pas
concevable de réaliser manuellement un dictionnaire par corpus : il faut
surtout être conscient des difficultés théoriques posées par le sens des mots.

On considèrera dans ce travail que les sens définis dans un dictionnaire
classique relèvent du «~domaine général~», et que les sens qui apparaissent
dans d'autres domaines sont des sens «~spécialisés~». Par exemple, le
dictionnaire DicoInfo \citep{corpusolst} spécialisé dans les domaines de
l'Informatique et d'Internet mentionne un sens spécifique pour le nom
\emph{compilation} : \emph{action effectuée par un compilateur qui consiste à
    transformer du code créé au moyen d'un langage de programmation évolué en
un langage compréhensible par l'ordinateur}. Ce sens est par exemple absent du
TLFi \citep{TLFi} parce qu'il ne faisait pas partie des sens du mot dans le
corpus utilisé pour établir les définitions.

\subsection{Ressources lexicales actuelles}
\label{subsec:ressources_lexicales}

D'autres moyens existent pour représenter le sens des mots. La qualité du
travail lexicographique exposé dans les dictionnaires n'a pas été remise en
cause, mais :

\begin{itemize}

    \item les dictionnaires traditionnels, même dans leur version en ligne, ne
        tirent pas profit des nouveaux moyen d'organisation rendus possibles
        avec un ordinateur : il n'est plus nécessaire de trier les mots, on
        peut les représenter par un graphe
        \citep{miller1990introduction,polguere2013tissage},

    \item les dictionnaires traditionnels sont basés sur l'histoire des mots au
        lieu de considérer les progrès en linguistique et psycholinguistique
        proposant des organisations plus utiles et plus proches du lexique
        mental \citep{miller1990introduction}.

\end{itemize}

De plus, l'utilisation de dictionnaires récents implique un coût d'achat et le
respect de la licence restrictive, ce qui explique que ces dictionnaires ont
rapidement étés abandonnés en TAL au profit d'autres ressources disponibles
sous une licence libre comme WordNet, Wikipédia ou encore le Wiktionnaire. En
effet, ces ressources autorisent une utilisation à la fois à des fins de
recherche mais aussi pour un usage commercial, ce qui leur a assuré une large
diffusion.

La première ressource lexicale à tirer partie de la possibilité de représenter
le lexique sous la forme d'un graphe est WordNet, décrit à la
section~\ref{presentation_wordnet}.

\citep{hovy2006ontonotes,ide2006making,navigli2007semeval,snow2007learning} ont
jugé que la trop grande finesse de distinction des sens de WordNet justifiait
une alternative avec des sens distingués plus grossièrement. Ce problème est
attribué selon \cite{edmonds2002introduction} au manque de rigueur
lexicographique de WordNet, et à la mise en avant de la similarité entre les
mots à travers les synsets au détriment de la distinction des sens de chaque
mot. Il s'est en effet avéré que l'accord inter-annotateurs pour un étiquetage
avec WordNet est faible : de l'ordre de 70\% \citep{snyder2004english}.
Utiliser un autre inventaire est un moyen efficace de s'adapter à différentes
applications \citep{palmer2004different}, ce qui a entraîné des travaux
utilisant des inventaires plus grossiers \citep{navigli2007semeval}.

Au-delà des fusions de synsets automatiques \citep{snow2007learning}, de
nouveaux inventaires de sens moins fins ont étés développés :

\begin{itemize}

    \item OntoNotes \citep{hovy2006ontonotes} a choisi de regrouper
        manuellement les sens WordNet jusqu'à obtenir un accord
        inter-annotateur de 90\%.

    \item DANTE\footnote{Les entrées pour les mots entre M et R sont
        disponibles sur http://webdante.com/} \citep{mccarthy2010dante} est un
        inventaire entièrement nouveau, conçu dans l'objectif de corriger les
        erreurs faites avec WordNet \citep{kilgarriff2010detailed}.

    \item Le Réseau Lexical du Français \citep{gader2014lexicon} lie des sens de
        mots avec de nombreuses fonctions lexicales associés à un degré de
        confiance, le tout permettant de produire des articles de dictionnaires.

\end{itemize}

Ces inventaires semblent plus adaptés que WordNet pour la désambiguïsation
lexicale \citep{navigli2012quick}, mais ils ne sont pas encore disponibles ou
ne sont pas utilisables librement à des fins commerciales.

Une approche complètement différente est celle de la structure de qualia
\citep{johnston1996qualia} qui s'inscrit dans le contexte plus général du
lexique génératif introduit par \cite{pustejovsky1991generative} et qui
considère qu'une approche énumérative n'est pas viable. Le sens d'un mot est
alors défini selon plusieurs aspects prédéfinis (constitution, rôles, facteurs
impliqués dans la création, etc.) qui peuvent se retrouver dans plusieurs mots.
Par exemple, un couteau contient une lame et sert à couper. Cette approche est
semblable à celle qui définit le sens d'un mot comme une liste de sèmes
\citep{rastier1987semantique}. À notre connaissance, CoreLex
\citep{buitelaar1998corelex} est le seul inventaire et système de
désambiguïsation lexicale suivant cette approche.

Enfin, différents travaux mentionnent la possibilité d'utiliser plus d'un sens
pour un mot donné. \cite{smith2011rumble} propose d'utiliser des distributions
de probabilité sur les différents sens possibles pour définir un sens précis
dans un corpus. Dans SemCor, les annotateurs pouvaient choisir plusieurs sens
si besoin, mais seulement 0.3\% des occurrences de SemCor sont étiquetées avec
plus d'un sens. \cite{erk2013measuring} montrent qu'un accord inter-annotateur
élevé peut être obtenu en demandant aux annotateurs d'indiquer pour chaque sens
sa correspondance avec l'usage sur une échelle de 1 à 5. Une campagne
d'évaluation a eu lieu en 2013 à ce sujet \citep{jurgens2013semeval}. Les
annotations obtenues avec Amazon Mechanical Turk ont été abandonnées au profit
de l'annotation par les deux organisateurs de la tâche. Dans les deux cas,
l'accord inter-annotateur était modéré, ce qui remet en question la pertinence
de l'annotation de différents sens fins.

\subsection{Modèles de langue pour la similarité sémantique}
\label{subsec:modeles_de_langue}

Un modèle de langue prédit la probabilité d'un mot étant donné son contexte
dans la phrase. Cette probabilité est directement utile pour des tâches telles
que la traduction automatique ou la reconnaissance de la parole dans lesquelles
un modèle de langue favorisera des phrases globalement plausibles au lieu
d'étudier chaque mot individuellement.

Ces modèles de langue permettent aussi d'obtenir des mesures de similarité
sémantiques utiles, ce qui est justifié par l'hypothèse distributionnelle
\cite[p.~786]{harris1954distributional} :

\begin{quote} ... si l'on considère que le sens de deux mots ou morphèmes A et B
    diffère davantage que le sens de A et C, alors on observe souvent que les
    distributions de A et B diffèrent davantage que les distributions de A et C.
    Autrement dit, la différence de sens est corrélée à la différence de
    distribution. \end{quote}

Les modèles de langue sont un moyen d'étudier ces distributions de probabilité.
On peut étudier deux types de distributions différentes correspondant à deux
types de relations entre les mots \citep{sahlgren2008distributional} :

\begin{itemize}
    \item les relations syntagmatiques identifient les mots qui sont présents
        ensemble dans un contexte donné ;
    \item les relations paradigmatiques identifient les mots qui sont présents
        dans un même contexte, mais sans y être présents ensemble.
\end{itemize}

Par exemple, étant donné les deux phrases \emph{Je bois du café} et \emph{Je
bois du thé}, on peut déduire que les lemmes \emph{boire} et \emph{thé} sont
liés par une relation syntagmatique : ils sont présents ensemble dans la
phrase. Au contraire, \emph{thé} et \emph{café} ne sont pas ici présents dans
la même phrase, mais apparaissent dans un même contexte (\emph{Je bois du}) :
ils sont liés par une relation paradigmatique.

Observer les distributions de contexte des mots peut séparer les mots en
différents sens selon l'usage de chaque sens
\citep{yarowsky1993one,pantel2002discovering,pedersen2010duluth}. Cependant,
dans la littérature que nous exposons et dans nos travaux, les modèles de
langue ne décrivent que des mots en confondant leurs différents sens. Nous ne
mentionnerons plus par la suite cette difficulté, en considérant (par
simplification) qu'il suffit que le modèle de langue décrive parmi tous les
sens le sens que nous souhaitons observer.

% TODO qu'a dit le monsieur dans l'invited talk à GWC 2014 ?
Comment observer ces distributions de probabilité ? Une façon d'opérer est de
calculer la probabilité d'un mot dans une phrase étant donné les mots
précédents. Par exemple, étant donné le début de phrase \emph{Au-delà des
approches ...}, on veut connaître la probabilité du mot suivant, en espérant
que celle de \emph{statistiques} ou \emph{supervisées} soit plus importante que
celle de \emph{chat}. En prenant par exemple le contexte des deux mots qui
précèdent le mot étudié, on calcule sa probabilité simplement avec le maximum
de vraisemblance :

\[
p(w_i|w_{i-2}, w_{i-1}) = \frac{compte(w_{i-2}, w_{i-1}, w_i)}{compte(w_{i-1}, w_i)}
\]

La séquence $w_{i-2}, w_{i-1}, w_{i}$ est un 3-gramme, et $compte$ indique le
nombre d'occurrences de cette séquence dans le corpus considéré. La taille du
contexte peut varier, ce qui est la raison pour laquelle on parle de manière
générale de n-grammes. Le nombre de paramètres à estimer pour obtenir une
distribution de probabilité conditionnelle fiable est $|V|^N$, $|V|$ étant la
taille du vocabulaire et $N$ la taille du contexte étudié. En considérant un
petit vocabulaire (10~000 mots) et un contexte de trois mots, il faut déjà
estimer $10^{9}$ probabilités, ce qui requiert un corpus très large : Google a
utilisé un corpus de livres de $10^{12}$ mots pour produire des n-grammes
allant jusqu'à $n=5$ \citep{brants2006web}. Diverses techniques de lissage
existent pour mieux répartir les probabilités obtenues par maximum de
vraisemblance \citep[Chapitre~4]{jurafsky2008speech}. En effet, la plupart des
probabilités sont initialement nulles, que ce soit parce que le n-gramme est
grammaticalement invalide ou simplement parce qu'il n'a pas été observé dans le
corpus étudié. Il faut alors estimer la probabilité de tels n-grammes à partir
d'un n-gramme plus court ou leur assigner une probabilité très faible.

Diverses extensions de ces modèles de langues à base de n-grammes existent,
l'une d'entre elles étant le modèle de langue syntaxique
\citep{lin1998automatic,goldberg2013dataset}. Dans ce modèle, on considère les
mots présents ensemble dans une relation syntaxique donnée. Pour la relation
complément du nom par exemple, on s'attend à ce que \emph{vélo} soit le
complément du nom des mots \emph{pédale}, \emph{guidon}, \emph{pneu}... Nous
utilisons pour la traduction de WordNet (Chapitre~\ref{ch:wonef}) un tel modèle
de langue syntaxique (\url{http://www.kalisteo.fr/demo/semanticmap/}).  Il a
été entraîné sur un corpus extrait du web francophone
\citep{grefenstette2007conquering}. Le corpus a ensuite été analysé par LIMA
\citep{besancon2010lima}, une chaîne d'analyse linguistique désormais libre ici
utilisée comme un analyseur syntaxique à base de règles produisant des
dépendances syntaxiques fines. Pour une relation donnée $r$ et un lemme $x$, le
modèle de langue indique quels sont les 100 premiers lemmes co-occurrant le
plus fréquemment avec $x$ dans la relation $r$.  Avec le mot \textit{avion} et
la relation de complément du nom, le mot \textit{billet} modifie le plus
\textit{avion} : \textit{billet d'avion} est fréquent dans le corpus.

% TODO petite figure ici ?

% TODO donner des raisons de l'efficacité, "exponentiel" tout ça

D'autres types de modèles de langue représentent les mots de manières
distribuée en utilisant un vecteur de nombres réels. La manière la plus
répandue pour faire cela est d'utiliser un réseau de neurones dont une des
couches sera le vecteur représentant chaque mot. \cite{hinton1986learning} a
d'abord proposé l'idée d'un réseau de neurones pour représenter des concepts à
l'aide de vecteurs faisant partie du réseau,
\cite{bengio2001neural,bengio2003neural} ont présenté le modèle de langue
neuronal tel qu'on le connaît aujourd'hui, et \cite{mikolov2013efficient} a
optimisé un modèle de langue en supprimant notamment une couche cachée pour
l'utiliser sur de plus gros corpus. Dans tous ces modèles, lors de la
rétropropagation du gradient, la représentation des mots évolue, ce qui a pour
effet de rapprocher la représentation des mots sémantiquement proches. Par
exemple, \cite{mikolov2013distributed} montre que la distance entre le mot
représentant un pays (par exemple \emph{Turkey}) et le mot représentant la
capitale de ce pays (ici \emph{Ankara}) correspond au vecteur du mot
\emph{capital}.  Ces représentations de mots peuvent être ensuite utilisées ou
apprises pour diverses tâches. Nous citerons ici l'extraction d'évènements
\citep{boros2014etiquetage}, l'annotation en rôles sémantiques
\citep{lechelle2014utilisation} et la traduction automatique
\citep{devlin2014fast}, mais toute tâche peut bénéficier d'améliorations (plus
ou moins importantes) de telle représentations de mots où les mots
sémantiquement proches sont proches dans la représentation choisie.  Ces
réseaux de neurones sont encore difficiles à entraîner et à paramétrer
\citep{do2014modeles}, mais représentent une alternative plus efficace que les
modèles de langue simples à base de n-grammes \citep{baroni2014dont}.

% TODO LSA fait une partie du chemin

Les réseaux de neurones ne sont qu'une façon d'obtenir de tels résultats. En
particulier, \cite{levy2014linguistic} montrent qu'une nouvelle mesure de
similarité permet d'obtenir des résultats similaires à
\cite{mikolov2013efficient}, ce qui montre le besoin de continuer à étudier les
réseaux de neurones pour mieux comprendre leur fonctionnement et savoir quand
leur utilisation est pertinente.

\section{Traductions de ressources linguistiques}
\label{sec:translation}

\subsection{WordNet}

WordNet reste une ressource extrêmement utile et reproduire ce travail pour
d'autres langues serait coûteux et difficile à maintenir. Malgré quelques
problèmes théoriques, traduire WordNet en gardant sa structure et ses synsets
mène à des ressources linguistiques utiles
\citep{fellbaum2007connecting,demelo2008utility}. Cependant, il n'existe encore
que peu d'équivalents de même qualité dans d'autres langues
\citep{bond2012survey}, et il est donc utile de s'atteler à la traduction de
cette ressource.

Les traductions automatiques de WordNet emploient une approche dite d'extension
(\textit{extend approach}) : la structure de WordNet est préservée et seuls les
littéraux sont traduits. Trois techniques principales représentent cette
approche dans la littérature. La plus simple utilise des dictionnaires
bilingues pour faciliter le travail des lexicographes qui filtrent ensuite
manuellement les entrées proposées
\citep{vossen1998eurowordnet,pianta2002developing,tufis2004balkanet}. Une
deuxième méthode de traduction utilise des corpus parallèles, ce qui évite
l'utilisation de dictionnaires qui peuvent entraîner un biais lexicographique.
\cite{dyvik2004translations} représente cette méthode en s'appuyant sur des
\textit{back-translations} entre le norvégien et l'anglais, alors que
\citep{sagot2008construction} combinent un lexique multilingue et les
différents WordNets de BalkaNet comme autant de sources aidant à la
désambiguïsation. Enfin, plus récemment, des ressources telles que Wikipédia ou
le Wiktionnaire ont été explorées. Grâce aux nombreux liens entre les
différentes langues de ces ressources, il est possible de créer de nouveaux
wordnets \citep{demelo2009towards,navigli2010babelnet} ou d'améliorer des
wordnets existants \citep{hanoka2012wordnet}.
% TODO mettre à jour l'état de l'art avec GWC 2014 et LREC 2014 ?

Concernant le français, l'EuroWordNet \citep{vossen1998eurowordnet} est la
première traduction française de WordNet. C'est une ressource d'une couverture
limitée qui demande des améliorations significatives avant de pouvoir être
utilisée \citep{jacquin2006systemes}, et qui n'est ni libre ni librement
accessible. WOLF est une seconde traduction initialement construite à l'aide de
corpus parallèles \citep{sagot2008construction} et étendue depuis avec
différentes techniques \citep{apidianaki2012applying}. WOLF est distribué sous
une licence libre compatible avec la LGPL et c'est aujourd'hui le WordNet
français standard. Enfin, JAWS \citep{mouton2010jaws} est une traduction des
noms de WordNet développée à l'aide de dictionnaires bilingues et d'un modèle
de langue syntaxique.

\label{subsec:jaws_translation_process}

Notre traduction de WordNet nommée WoNeF (Chapitre~\ref{ch:wonef}) est le
successeur de JAWS \citep{mouton2010jaws,mouton2010phd} que nous présentons
ici. Le Chapitre~\ref{ch:wonef} liste les différences avec JAWS : il est donc
nécessaire d'avoir compris le fonctionnement de JAWS avant de le lire.

JAWS repose sur un algorithme faiblement supervisé qui ne demande aucune donnée
annotée manuellement. Pour traduire un wordnet source, JAWS s'appuie sur un
dictionnaire bilingue et un modèle de langue syntaxique pour la langue cible.
Le dictionnaire bilingue est une concaténation du dictionnaire bilingue
SCI-FRAN-EurADic\footnote{\url{http://catalog.elra.info/product_info.php?products_id=666}}
et des liens entre les Wiktionnaires français et
anglais\footnote{\url{http://www.wiktionary.org/}}. Le modèle de langue
syntaxique a été présenté à la section~\ref{subsec:modeles_de_langue}. Grâce
aux dictionnaires, JAWS n'a pas besoin de sélectionner les littéraux de chaque
synset parmi l'ensemble du vocabulaire mais seulement parmi un petit nombre de
candidats (9 en moyenne).  Le processus de traduction se fait en trois étapes :

\begin{enumerate}
    
    \item Créer un wordnet vide : la structure de WordNet est préservée, mais
        les synsets eux-mêmes n'ont pas de littéraux associés.

    \item Choisir les traductions les plus faciles parmi les candidats des
    dictionnaires pour commencer à remplir JAWS.

    \item Étendre JAWS de manière incrémentale en utilisant le modèle de
        langue, les relations entre synsets et le JAWS déjà existant.

\end{enumerate}

\paragraph{Sélecteurs initiaux} Quatre algorithmes que nous nommons sélecteurs
initiaux choisissent des traductions correctes parmi celles qui sont proposées
par les dictionnaires.

\begin{itemize}

    \item Premièrement, les mots qui apparaissent dans un seul synset ne sont
        pas ambigus et il suffit d'ajouter toutes leurs traductions au WordNet
        français : c'est le sélecteur par monosémie. C'est le cas de
        \textit{grumpy} : toutes ses traductions sont validées dans le synset
        où il apparaît.

    \item Deuxièmement, le sélecteur par unicité identifie les mots n'ayant
        qu'une seule traduction et la valident dans tous les synsets où cette
        traduction est présente. Les cinq synsets contenant \textit{pill} en
        anglais sont ainsi complétés avec \textit{pilule}.

    \item Un troisième sélecteur vise à traduire les mots qui ne sont pas dans
        le dictionnaire en utilisant directement la traduction anglaise : c'est
        le sélecteur des transfuges.

    \item Un quatrième sélecteur utilise la distance d'édition de Levenshtein :
        si la distance entre un mot anglais et sa traduction est petite, on
        peut considérer que c'est le même sens (c'est le cas par exemple pour
        \textit{portion} ou encore \textit{university}), malgré l'existence de
        certains faux amis. Ces quatre sélecteurs produisent une première
        version du WordNet français qui contient assez de traductions pour
        pouvoir ensuite utiliser le modèle de langue et continuer de compléter
        les synsets.

\end{itemize}

\paragraph{Expansion de JAWS} JAWS étant partiellement rempli, une nouvelle étape d'expansion tire parti des relations entre les synsets de WordNet pour valider de nouvelles traductions. Par exemple, si :

\begin{itemize}

    \item un synset S1 est méronyme d'un synset S2 dans WordNet,

    \item dans notre modèle de langue, un littéral de S1 est méronyme d'un
        littéral candidat C dans S2,

\end{itemize}

alors ce littéral est considéré comme correct. La tâche de traduction est ainsi
réduite à une tâche de comparaison entre d'une part les relations lexicales
entre les synsets de WordNet et d'autre part les relations lexicales entre les
lexèmes du français.

Prenons l'exemple de \textit{quill} qui peut se traduire par \textit{piquant}
ou \textit{plume} (Figure \ref{meronymyexample}). Dans WordNet, \textit{quill}
est méronyme de \textit{porcupine} qui a déjà été traduit par
\textit{porc-épic} par un sélecteur initial. Dans le modèle de langue,
\textit{piquant} fait partie des compléments du noms de \textit{porc-épic} mais
ce n'est pas le cas de \textit{plume}. Ici, la relation de complément du nom
implique la méronymie et c'est donc \textit{piquant} qu'il faut choisir comme
la traduction correcte de \textit{quill}. Le modèle de langue a permis la
désambiguïsation parmi les deux traductions possibles.

\tikzstyle{block}=[draw, fill=blue!5, rectangle, minimum height=0.5cm, minimum width=3cm, text width=5cm]

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[auto, node distance=2cm,>=latex']
    % Inspired from http://www.texample.net/tikz/examples/control-system-principles/
    % first place and connect the outer blocks that represent synsets
      \node [block, text width=5cm] (quill) {~\\\textbf{Synset S1} \\ - Anglais : quill \\ - Français : piquant? plume? \\ (a stiff hollow protective spine on a porcupine) \\ ~ };
      \node [block, text width=4.0cm, right of=quill, node distance=9cm] (porcupine) {\textbf{Synset S2} \\ - Anglais : porcupine, hedgehog \\ - Français : porc-épic \\ (rodents with sharp erectile bristles mingled with the fur)};
    \draw [<-] (porcupine) -- node[above] {méronyme de} (quill);
    \draw [<-] (porcupine) -- node[below] {(relation WordNet)} (quill);

    % then the syntactic model relations
    \node [block, below of=porcupine, text width=4.0cm, node distance=3cm] (porcupinesynt1) {porc-épic};
    \node [block, below of=quill, node distance=3cm] (quillsynt1) {\Large{mémoire}, \Large{piquant}, \large{poil}, \large{épine}, yéti, ragoût, grotte, \small{tactique}, \small{pelage}, \small{dextre}, \small{aiguille}, ...};
    \draw [<-] (porcupinesynt1) -- node[above] {complément du nom de} (quillsynt1);
    \draw [<-] (porcupinesynt1) -- node[below] {(modèle de langue)} (quillsynt1);

  \end{tikzpicture}
  \caption{\protect\centering\label{meronymyexample}Traduction via la relation de méronymie de partie.}
\end{figure}

Un problème potentiel avec cette approche est que la relation de complément du
nom n'est pas limitée à la méronymie. Par exemple, le mot \textit{mémoire} qui
apparaît dans le modèle de langue vient d'un livre intitulé \textit{Mémoires
d'un porc-épic}. Heureusement, \textit{mémoire} n'est pas dans les candidats de
\textit{quill} et ne peut pas être choisi comme une traduction. Paradoxalement,
le modèle de langue ne peut pas choisir entre deux mots très différents, mais
est capable de faire le bon choix parmi les différentes traductions d'un mot
polysémique. Alors que traduire WordNet automatiquement avec un dictionnaire ou
un modèle de langue syntaxique est impossible, combiner les deux sources
d'information permet de résoudre le problème.

Chaque sélecteur suit le même principe que le sélecteur par méronymie de partie
et traduit de nouveaux synsets en identifiant les relations entre lexèmes via
le modèle de langue syntaxique. La correspondance entre la relation de
complément du nom et la relation de méronymie est directe, mais ce n'est pas le
cas pour les autres relations : il n'y a par exemple pas de relation syntaxique
qui exprime directement la synonymie entre deux lexèmes. Pour ces relations, il
est nécessaire d'employer soit des motifs lexicaux \citep{hearst1992automatic}
soit des relations paradigmatiques \citep{lenci2012identifying}. Ce sont ces
dernières (section~\ref{subsec:modeles_de_langue}) que JAWS utilise. Pour la
synonymie, si deux mots partagent les mêmes co-occurrents dans une relation
syntaxique donnée, alors ils peuvent être synonymes dans ce contexte. Pour les
noms, les relations syntaxiques qui donnent les meilleurs résultats sont les
relations de complément du nom, d'objet du verbe et d'apposition. Concrètement,
si deux noms qui modifient les mêmes noms sont les objets des mêmes verbes ou
sont apposés aux mêmes noms, alors il est probable qu'ils soient synonymes et
si l'un des deux est déjà dans un synset, alors on peut y ajouter le second.
Par exemple, \textit{avant-propos} et \textit{préface} partagent les mêmes
compléments du noms : \textit{livre, édition, ouvrage}. Le sélecteur par
synonymie peut ajouter \textit{avant-propos} une fois que le littéral
\textit{préface} est dans JAWS. \citep{mouton2010jaws,mouton2010phd} décrivent
d'autres sélecteurs exploitant notamment les relations d'hyperonymie et
d'hyponymie.

\subsection{VerbNet}

\cite{merlo2002multilingual} ont utilisé des similarités entres langues pour
convertir 20 classes de Levin vers l'Italien. Des acquisitions automatiques ont
aussi été menées en japonais \citep{suzuki2009classifying}, allemand
\citep{im2006experiments} et espagnol \citep{ferrer2004towards}. Les seules
traductions directes dont nous avons la connaissance sont le VerbNet estonien
\citep{jentson2014verbnet} et le VerbNet portuguais brésilien
\citep{scarton2012towards} qui utilise des mappings entre VerbNet et WordNet,
et entre WordNet.Br et WordNet.

Pour le français, \cite{saintdizier1996constructing} a produit une ressource
proche des classes de Levin. À notre connaissance, l'effort sur cette ressource
s'est arrêté et le résultat n'est pas disponible. Des travaux se sont ensuite
concentrés sur l'acquisition automatique de cadres de sous-catégorisation et
sur le regroupement de verbes en se basant sur ces cadres et sur des
similarités sémantiques. \cite{sun2010investigating} ont utilisé un large
lexique de cadres de sous-catégorisation \citep{messiant2010acquisition} pour
regrouper les verbes en clusters à l'aide de traits sémantiques (colocations et
préférences lexicales des verbes) et syntaxiques (cadres de
sous-catégorisation). L'évaluation sur une vérité-terrain créée manuellement a
mené à une F-mesure de 55.1\%. \cite{falk2012classifying} appliquent un
algorithme de clustering différent et utilisent des features différentes, ce
qui améliore la F-mesure sur la même vérité-terrain mais simplifiée, ce qui
donne une F-mesure de 70\%. Ces ressources mettent en valeur de nouvelles
façons de séparer les verbes du Français, mais les erreurs qu'elles contiennent
seront une nouvelle source d'erreur dans les applications : il est important de
les corriger si possible.


\section{Annotation en rôles sémantiques}
\label{sec:srl}

Nous étudions les différentes façons de définir les rôles sémantiques,
examinons diverses ressources utiles pour la tâche d'annotation, et présentons
les techniques principales pour réaliser l'annotation elle-même.

% TODO définir frame ?

\subsection{Les rôles sémantiques}
\label{subsec:roles_semantiques}

Comment aller au-delà d'une analyse syntaxique pour représenter le sens d'une
phrase ? La notion de rôle sémantique semble particulièrement adaptée aux
approches statistiques que nous présentons ici. Ces rôles ont pour objectif de
s'abstraire des alternances de diathèse présentes dans le langage naturel
(Figure~\ref{fig:example_srl}). Différentes théories linguistiques proposent
différentes représentations pour ces rôles ; nous nous intéresserons ici aux
rôles VerbNet et à la théorie élaborée par \cite{fillmore1968case} qui établit
que le cas grammatical exhibe des relations profondes et sémantiques. De
nombreuses langues marquent ces relations au niveau morphologique ; l'élatif
est un exemple de cas grammatical qui exprime le lieu de l'intérieur duquel
provient un mouvement et qui est marqué morphologiquement en finnois, hongrois
et estonien. Il est alors sensé de prévoir un rôle sémantique pour ce cas
grammatical, même s'il n'est pas marqué au niveau morphologique dans la langue
étudiée.
% TODO clarifier

Il n'y a pas de réel consensus sur un inventaire de cas donnés. Parmi les rôles
sémantiques généralement acceptés, on peut citer :

\begin{itemize}
    \item l'\textbf{Agent} qui est à l'origine de l'action
    \item le \textbf{Patient} qui subit un changement d'état
    \item l'\textbf{Instrument} utilisé pour réaliser l'action
    \item le \textbf{Bénéficiaire} qui tire profit de l'action
\end{itemize}

\subsection{Lexiques et corpus}

% TODO Groningen Meaning Bank (GMB)

Il existe en anglais différentes ressources pour l'annotation en rôles
sémantique : nous aborderons ici FrameNet, PropBank et NomBank, VerbNet ayant
déjà été présenté plus longuement à la
section~\ref{presentation_verbnet}. 

\paragraph{FrameNet}
\label{presentation_framenet}

% TODO move out to introduction

FrameNet \citep{baker1998berkeley} repose sur la théorie des \textit{Frame
Semantics}, élaborée par Fillmore en modifiant sa théorie initiale. Ici, les
rôles sémantiques \textit{frame elements} sont spécifiques à chaque situation
(\textit{frame}) tout en se recoupant par endroits. On retrouve ainsi le rôle
d'agent, mais aussi des rôles spécifiques comme \textbf{Food} dans
\textbf{Apply\_heat} ou \textbf{Completeness} dans \textbf{Activity\_pause}.
Les rôles sont classifiés selon leur importance dans la situation : centraux
(nécessaires), périphériques (toujours liés à la situation mais optionnels) et
circonstanciels (potentiellement présent dans toutes les situations, par
exemple le lieu ou le temps).

\paragraph{PropBank}

Malgré quelques critiques \citep{riemer2011conception}, l'interface
syntaxe-sémantique nous permet d'utiliser les informations syntaxiques d'un
verbe pour distinguer différents sens et identifer ses arguments sémantique.
Par exemple, nous pouvons expliquer la différence entre deux sens majeurs du
verbe « retenir » ainsi :

\begin{enumerate}
    \item se souvenir de quelque chose
    \item empêcher quelqu'un de faire quelque chose
\end{enumerate}

PropBank \citep{palmer2005proposition} a décidé d'utiliser les annotations
syntaxiques du Penn TreeBank \citep{marcus1993building} pour annoter en rôles
sémantiques les phrases incluant un des 5000 verbes les plus fréquents du
corpus. Pour chaque phrase, les annotateurs ont identifié les syntagmes jouant
un rôle sémantique. L'objectif principal de PropBank est de permettre
d'utiliser l'apprentissage automatique pour l'annotation en rôles sémantiques.
C'est pour cette raison que les étiquettes disponibles sont très générales.
Ainsi, il est fréquent que \textit{ARG0} désigne l'agent, \textit{ARG1} le
patient. D'autres arguments sont disponibles pour étiqueter des rôles plus
spécifiques (\textit{ARG2}, \textit{ARG3}, etc.) ainsi que des rôles
secondaires (\textit{Location}, \textit{Extent}, \textit{Manner}, etc.)

\paragraph{NomBank}

NomBank \citep{meyers2004nombank} a été conçu à l'image de PropBank. La
spécificité de cette ressource est de se concentrer sur les noms communs, plus
particulièrement sur les 5~000 noms communs les plus fréquents dans le Penn
TreeBank. Sur le million de mots présent dans le corpus, 250 000 sont des noms
communs. 100 000 d'entre eux sont des noms issus d'un verbe ou qui se
comportent à la façon d'un verbe. Par exemple, le nom commun français « achat »
est lié au verbe « acheter », et les arguments sémantiques seront probablement
les mêmes : dans « Il a acheté un arbre » et « l'achat d'un arbre »,
\textit{ARG1} sera dans les deux cas l'arbre. D'autres catégories incluent les
noms partitifs, relationnels et environnementaux.

Pour une phrase telle que \emph{They gave the chefs a standing ovation}, les
annotations PropBank et NomBank peuvent montrer les liens possibles entre ces
deux ressources. Cette similarité volontaire a permis de lier ces ressources
\citep{pustejovsky2005merging,verhagen2007combining}, mais des applications
utilisant de telles ressources unifiées doivent encore voir le jour.

\cite{gerber2010beyond} ont étendu NomBank aux arguments
implicites, améliorant ainsi la couverture de NomBank de 65\%, c'est-à-dire en
augmentant le nombre moyen de rôles remplis dans chaque exemple annoté. Il
n'est pas rare que les arguments soient implicites mais présent dans d'autres
phrases. Les annotations étant limitées à la phrase actuelle, il n'est pas
possible de référer à un argument présent dans une prase précédente.

Enfin, PropBank a récemment décidé d'inclure d'autres parties du discours : les
noms, les adjectifs, et les verbes support \citep{bonial2014propbank}.

\subsection{Approches d'annotation}

Les systèmes d'annotation en rôles sémantiques utilisent deux types de
ressources :

\begin{enumerate}
    \item Les \textbf{inventaires} examinés à la section précédente permettent
        de fournir un socle commun à différents systèmes. Ce sera par exemple
        la définition des frames, des rôles, des cadre de sous-catégorisation
        et des prédicats possibles.
    \item Les \textbf{corpus annotés} par des humains qui utilisent un
        inventaire donné pour réaliser la tâche qu'on essaie de faire apprendre
        aux systèmes. FrameNet contient de nombreux exemples annotés en plus
        des rôles sémantiques définis pour chacune des situations.
\end{enumerate}

Ces ressources sont utilisées différemment suivant les méthodes, souvent
divisées en trois approches générales : supervisées, fondées sur la
connaissance et non supervisées.

\paragraph{Supervisées}

Les méthodes supervisées
\citep{gildea2002automatic,surdeanu2008conll,das2014frame,hermann2014semantic}
utilisent un corpus annoté, et adoptent donc l'inventaire associé. Des
techniques classiques d'apprentissage automatique sont utilisées pour
déterminer le sens correct de chaque occurrence d'un mot étant donné les
informations obtenues à partir du contexte de cette occurrence.  L'annotation
en rôles sémantiques supervisée est souvent divisée en plusieurs sous-tâches :
l'identification des prédicats, puis des frames, l'identification des arguments
qui établit les syntagmes jouant un rôle dans la phrase et la classification
des rôles qui détermine le rôle effectif de chaque syntagme parmi ceux retenus
à la phase précédente.

Ces méthodes supervisées ont des difficultés pour couvrir un large éventail de
phrases. FrameNet est un travail colossal qui est encore loin de couvrir un
éventail complet du vocabulaire anglais \citep[p.~155]{marquez2008semantic}.
% TODO check citation marquez
% TODO citer différents FrameNets ? Copa 2014 Bresil FrameNet ?
% TODO citer traduction mouton
% TODO citer traduction apidianaki http://www.aclweb.org/anthology/C/C14/C14-1121.pdf

% TODO citer méthodes basées sur word2vec : lechelle2014, kanerva2014 http://www.aclweb.org/anthology/W/W14/W14-1501.pdf

% TODO citer konstas2014incremental
% TODO citer lluis2014shortest
% TODO citer yang2014multi

% TODO roth2014composition (word repr composition improves SRL)


\paragraph{Fondées sur la connaissance}

Contrairement aux approches supervisées, ces approches n'utilisent pas de
corpus annoté \citep{swier2005exploiting,pradet2013revisiting}. Les systèmes
s'affranchissent alors de la petite taille inhérente à tout corpus annoté et
peuvent utiliser un large corpus non annoté tel que le web. Un inventaire de
sens est tout de même utilisé, et il faut toujours faire de la classification ;
la difficulté principale étant ici d'obtenir des informations utiles à partir
des exemples non annotés. Étant donné que ces méthodes continuent à utiliser un
inventaire, il reste possible de comparer les résultats entre différents
systèmes et de réaliser une évaluation sur une vérité-terrain. Il est toujours
possible d'utiliser un corpus pour régler les paramètres à l'aide d'un
échantillon de validation ou comme base pour annoter de nouveaux exemples ;
mais des corpus plus conséquents sont toujours utilisés.

\paragraph{Non supervisées}

% TODO Need ref

Ces approches n'utilisent aucune connaissance \textit{a priori}, que ce soit un
inventaire ou un corpus annoté. Une approche non supervisée doit nécessairement
construire son propre inventaire. Cette construction peut se faire via du
\textit{clustering} de sens à partir des occurrences de contextes trouvées dans
le corpus, en considérant l'hypothèse distributionnelle (section
\ref{subsec:modeles_de_langue}). Une fois que l'inventaire de sens est défini, il
faut l'utiliser pour étiqueter le texte.

Les avantages potentiels sont nombreux. Ces algorithmes ne nécessitent aucune
ressource, et offrent de fait deux propriétés intéressantes :

\begin{itemize}

    \item L'inventaire choisi colle au plus près du corpus utilisé, ce qui lui
        permet à la fois d'éviter des distinctions trop fines et de s'adapter à
        de nouveaux domaines via de nouveaux corpus, le domaine ayant un impact
        important sur les sens utilisés.

    \item Plus la quantité de texte disponible augmente, plus le système peut
        devenir efficace.

\end{itemize}

Malheureusement, les systèmes utilisant une approche non supervisée sont
difficiles à évaluer et à utiliser directement dans des systèmes plus
importants. Par exemple, dans le cadre de la traduction automatique, distinguer
les sens ne suffit pas ; il faut aussi savoir quelle traduction appliquer.

\subsection{Adaptation au domaine}

\cite{chen2008learning} entraînent un système de commentaires en utilisant des
commentaires existants et des simulations de jeux de football, mais sans
connaissance explicite sur la langue anglaise. Leur approche a entraîné des
travaux sur le \emph{situated language understanding} (compréhension ancrée du
langage): \cite{bordes2010towards,richardson2012towards} ont proposé par la
suite d'autres corpus pour cette tâche. Notre système
(Chapitre~\ref{ch:domainsrl}) est similaire dans le sens où nous minimisons
l'effort humain pour annoter de nouveaux domaines, mais nous nous concentrons
sur l'annotation en rôles sémantiques \emph{à la FrameNet}.

Le système d'annotation en rôles sémantiques de \cite{gormley2014low} n'a pas
besoin de syntaxe supervisée, mais nécessite un corpus annoté en rôles
sémantiques. \cite{hadouche2011annotation} effectue une annotation en rôles
sémantiques sur le corpus DicoInfo \citep{corpusolst} à l'aide de deux
approches :

\begin{itemize}
    \item en appliquant des règles définies manuellement s'appliquant à la
        sortie d'un analyseur syntaxique,
    \item en apprenant un système supervisé en utilisant divers traits issus de
        la littérature.
\end{itemize}

Ce travail conclut en indiquant que pour obtenir de meilleurs résultats sur
plus de rôles et de prédicats, il faut plus d'exemples d'entraînement. Notre
travail prend une autre direction : nous étudions l'utilisation de moins de
données créées manuellement pour couvrir plus de phrases dans divers domaines.
