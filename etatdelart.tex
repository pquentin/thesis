% vim: set spelllang=fr:

\setchapterpreamble[ur][.7\textwidth]{%
  \dictum[Robin Hobb, \textit{La Voie royale}]{%
  Un jour, alors que je venais de connaître Burrich, il m'avait ordonné de
  défaire le harnais d'un équipage de chevaux. [...] Quand Burrich revint voir
  ce qui me prenait tant de temps, il demeura muet de stupéfaction mais ne put
  me reprocher de n'avoir pas obéi à son ordre. Quant à moi, j'étais effaré du
  nombre de pièces qui entraient dans la composition d'un objet apparemment
  d'une seule pièce quand je m'y étais attaqué. J'avais la même impression sur
  la route : tous ces sons pour faire un mot, tous ces mots pour former une
  pensée ! Le langage tombait en morceaux entre mes mains. Jamais je n'y avais
  réfléchi.}}

\chapter{État de l'art} 
\label{ch:etatdelart} 

La représentation du sens des mots (section~\ref{sec:mots}) occupe une place
importante dans nos travaux, en particulier pour la traduction de la ressource
WordNet (Chapitre~\ref{ch:wonef}). La traduction de ressources lexicales
(section~\ref{sec:translation}) est un moyen de faire profiter une langue cible
d'une ressource existante dans une autre langue, comme nous le faisons dans la
partie~\ref{part:translation}. Enfin, l'annotation en rôles sémantiques
(section~\ref{sec:srl}) sera, elle, surtout utile pour la
partie~\ref{part:srl}.

\section{Représentation des mots}
\label{sec:mots}

Nous abordons certains aspects du sens des mots à travers l'étude de
différentes ressources lexicales, en commençant par les dictionnaires. Nous
présentons ensuite les modèles de langue qui sont une manière directe de
représenter les mots et leurs sens à partir d'un corpus brut.

\subsection{Représentation du sens des mots}
\label{subsec:sens_mots}

«~La lexicographie est la science qui consiste à recenser les mots, les
classer, les définir et les illustrer, par des exemples ou des expressions,
pour rendre compte de l'ensemble de leurs significations et de leurs acceptions
au sein d'une langue, afin de constituer un dictionnaire~»
\citep{wikipedia2014lexicographie}. La lexicographie est donc un socle sur
lequel le Traitement Automatique des Langues peut s'appuyer pour représenter le
sens des mots.

Pour pouvoir identifier les différents sens d'un mot, les lexicographes
n'opèrent plus par intuition linguistique \citep{kilgarriff1997don}. Ils
commencent par établir un corpus équilibré et de taille assez importante pour
représenter la langue étudiée. Ce corpus peut par exemple être constitué de
textes de journaux, de fiction, ou encore de blogs, le tout étant supposé être
représentatif de ce qu'une personne lambda lit durant sa vie. Pour un mot
donné, le lexicographe examine ses différents usages dans ce corpus à l'aide
d'un concordancier dans le but de séparer ces différents usages en sens.
Certains sens, jugés trop peu fréquents, sont laissés de côté. Le lexicographe
étudie ensuite la séparation obtenue pour établir des critères objectifs
distinguant les différents sens du mot étudié. Une phase d'ajustement de la
séparation suit pour vérifier que les critères ont été correctement appliqués,
ce qui peut amener à raffiner ces critères. Une fois les critères définitifs
établis, la définition peut être rédigée, les occurrences étudiées pouvant
servir d'exemples. L'avantage principal est que le processus lexicographique
est basé sur des données réelles et non pas sur des intuitions linguistiques.

Ainsi, les sens ne sont pas définis en tant que tels, mais sont avant tout des
occurrences dans un contexte donné. C'est une façon de comprendre la citation
de \citep{firth1957synopsys} : \textit{You shall know a word by the company it
keeps}\footnote{Vous devriez connaître un mot par ce qui l'accompagne.}. En
effet, selon \citep{kilgarriff1997don}, un ensemble de sens n'est défini que
par rapport à un corpus, et il est illusoire de vouloir définir un dictionnaire
parfait pour tous les sens possibles d'un mot. Néanmoins, il n'est pas
concevable de réaliser manuellement un dictionnaire par corpus : il faut
surtout être conscient des difficultés théoriques posées par le sens des mots.

On considèrera dans ce travail que les sens définis dans un dictionnaire
classique relèvent du «~domaine général~», et que les sens qui apparaissent
dans d'autres domaines sont des sens «~de spécialité~». Par exemple, le
dictionnaire DicoInfo \citep{corpusolst} spécialisé dans les domaines de
l'Informatique et d'Internet mentionne un sens spécifique pour le nom
\textit{compilation} : \textit{action effectuée par un compilateur qui consiste
    à transformer du code créé au moyen d'un langage de programmation évolué en
un langage compréhensible par l'ordinateur}. Ce sens est notamment absent du
TLFi \citep{TLFi} parce qu'il ne faisait pas partie des sens du mot dans le
corpus utilisé pour établir les définitions. Le lexique \textit{Les Verbes
Français} (section~\ref{sec:lvflg}) contient bien le sens informatique du verbe
\textit{compiler} mais le domaine (Informatique) et le niveau de lexique (5,
soit «~grands dictionnaires de langue ou encyclopédiques, lexiques
spécialisés~») indiquent bien que c'est un sens de spécialité.

\subsection{Ressources lexicales actuelles}
\label{subsec:ressources_lexicales}

D'autres moyens existent pour représenter le sens des mots. La qualité du
travail lexicographique exposé dans les dictionnaires n'a pas été remise en
cause, mais :

\begin{itemize}

    \item les dictionnaires traditionnels, même dans leur version en ligne, ne
        tirent pas profit des nouveaux moyen d'organisation rendus possibles
        avec un ordinateur : il n'est plus nécessaire de trier les mots, on
        peut les représenter par un graphe
        \citep{miller1990introduction,polguere2013tissage},

    \item les dictionnaires traditionnels sont basés sur l'histoire des mots au
        lieu de considérer les progrès en linguistique et psycholinguistique
        proposant des organisations plus utiles et plus proches du lexique
        mental \citep{miller1990introduction}.

\end{itemize}

De plus, l'utilisation de dictionnaires récents implique un coût d'achat et le
respect de la licence restrictive, ce qui explique que ces dictionnaires ont
rapidement étés abandonnés au profit d'autres ressources généralement
disponibles sous une licence libre comme WordNet, Wikipédia ou encore le
Wiktionnaire. En effet, ces ressources autorisent une utilisation à la fois à
des fins de recherche mais aussi pour un usage commercial, ce qui leur a assuré
une large diffusion.

La première ressource lexicale à tirer partie de la possibilité de représenter
le lexique sous la forme d'un graphe est WordNet, décrit à la
section~\ref{presentation_wordnet}.

\cite{hovy2006ontonotes,ide2006making,navigli2007semeval,snow2007learning} ont
jugé que la trop grande finesse de distinction des sens de WordNet justifiait
une alternative avec des sens distingués plus grossièrement. Ce problème est
attribué selon \cite{edmonds2002introduction} au manque de rigueur
lexicographique de WordNet, et à la mise en avant de la similarité entre les
mots au détriment de la distinction des différents sens de chaque mot. Il s'est
en effet avéré que l'accord inter-annotateurs pour un étiquetage avec WordNet
est faible : de l'ordre de 70\% \citep{snyder2004english}.  Utiliser un autre
inventaire est un moyen efficace de s'adapter à différentes applications
\citep{palmer2004different}, ce qui a entraîné des travaux utilisant des
inventaires plus grossiers \citep{navigli2007semeval}.

Au-delà des fusions de synsets automatiques \citep{snow2007learning}, de
nouveaux inventaires de sens moins fins ont étés développés :

\begin{itemize}

    \item OntoNotes \citep{hovy2006ontonotes} a choisi de regrouper
        manuellement les sens WordNet jusqu'à obtenir un accord
        inter-annotateur de 90\%.

    \item DANTE\footnote{Les entrées pour les mots entre M et R sont
        disponibles sur \url{http://webdante.com/}.} \citep{mccarthy2010dante} est un
        inventaire entièrement nouveau conçu dans l'objectif de corriger les
        erreurs faites avec WordNet \citep{kilgarriff2010detailed}.

    \item Le Réseau Lexical du Français \citep{polguere2014principes} lie des sens de
        mots avec de nombreuses fonctions lexicales associés à un degré de
        confiance, le tout permettant de produire des articles de dictionnaires.

\end{itemize}

Ces inventaires semblent plus adaptés que WordNet pour la désambiguïsation
lexicale \citep{navigli2012quick}. Cependant, les deux premiers ne sont pas
librement utilisables (en particulier à des fins commerciales) et le troisième,
bien qu'il sera diffusé sous une licence libre, n'est pas encore terminé.

Une approche complètement différente est celle de la structure de qualia
\citep{johnston1996qualia} qui s'inscrit dans le contexte plus général du
lexique génératif introduit par \cite{pustejovsky1991generative} et qui
considère qu'une approche énumérative n'est pas viable. Le sens d'un mot est
alors défini selon plusieurs aspects prédéfinis (constitution, rôles, facteurs
impliqués dans la création, etc.) qui peuvent se retrouver dans plusieurs mots.
Par exemple, un couteau contient une lame et sert à couper. Cette approche est
semblable à celle qui définit le sens d'un mot comme une liste de sèmes
\citep{rastier1987semantique}. À notre connaissance, CoreLex
\citep{buitelaar1998corelex} est le seul inventaire et système de
désambiguïsation lexicale suivant cette approche.

Différents travaux mentionnent la possibilité d'utiliser plus d'un sens pour un
mot donné. \cite{smith2011rumble} propose d'utiliser des distributions de
probabilité sur les différents sens possibles pour définir un sens précis dans
un corpus. Dans SemCor, les annotateurs pouvaient choisir plusieurs sens si
besoin, mais seulement 0.3\% des occurrences de SemCor sont étiquetées avec
plus d'un sens. \cite{erk2013measuring} montrent qu'un accord inter-annotateur
élevé peut être obtenu en demandant aux annotateurs d'indiquer pour chaque sens
sa correspondance avec l'usage sur une échelle de 1 à 5. Une campagne
d'évaluation a eu lieu en 2013 à ce sujet \citep{jurgens2013semeval}. Les
annotations obtenues avec Amazon Mechanical Turk ont été abandonnées au profit
de l'annotation par les deux organisateurs de la tâche. Dans les deux cas,
l'accord inter-annotateur était modéré, ce qui remet en question la pertinence
de l'annotation graduée de chacun des sens de l'inventaire.

Dans le cadre de l'adaptation aux domaines, d'autres travaux s'attachent à la
prise en compte du changement des sens suivant les domaines.
\cite{agirre2010semeval17} ont proposé une campagne d'évaluation sur le domaine
environnemental en anglais, chinois, néerlandais et italien. Pour chacune des
langues, au moins un système a battu la baseline du sens le plus fréquent, et
les systèmes fondés sur connaissance ont pu s'adapter au domaine plus
facilement que les systèmes supervisés. Les scores maximaux, entre 52~\% et
57~\%, restent loin de l'accord inter-annotateur, compris entre 72~\% et 96~\%.
En fouille d'opinion, \cite{marchand2014influence} évaluent eux l'apport de la
prise en compte du changement de polarité des mots lors d'un changement de
domaine. Par exemple, il s'avère que les termes mélioratifs au passé tels que
«~I loved~» sont plutôt positifs pour le cinéma ou le théâtre et plutôt négatif
en cuisine ou électroménager. Dans un cas, on parle simplement de la séance au
passé ; dans l'autre, on aimait l'objet au début mais ce n'est plus le cas. Un
autre exemple est l'adjectif «~imprévisible~» : c'est une qualité pour un film,
et un défaut pour de l'électroménager.

Contrairement aux systèmes généraux de désambiguïsation lexicale qui cherchent
à choisir un sens parmi un ensemble donné de sens, \cite{marchand2014influence}
ne s'intéressent qu'aux changements de sens utiles pour l'application, ce qui
rend le système plus robuste. Différentes tâches bénéficiant de tels
«~inventaires~» spécifiques ont ainsi étés proposées lors de campagnes
d'évaluation, en particulier SemEval. Par exemple :

\begin{itemize}
    \item la simplification lexicale
\citep{specia2012semeval1,fabre2014presentation},
    \item l'induction de sens et la désambiguïsation lexicale pour le
groupement de résultats en recherche d'information \citep{navigli2013semeval11},
    \item ou la traduction de fragments en langue natale (L1) dans un texte
écrit dans une langue apprise (L2) \citep{vangompel2014semeval5}
\end{itemize}

Enfin, une tendance récente facilitée par l'existence de ressources telles que
WordNet, Wikipédia ou le Wiktionnaire dans de nombreuses langues est de
représenter les sens des mots dans différentes langues simultanément
\citep{navigli2013babelnet}. Lors de SemEval-2010 \citep{lefever2010semeval3},
les meilleurs systèmes de la campagne utilisaient des corpus parallèles. Lors
d'une tâche proche à SemEval-2013 \citep{navigli2013semeval12}, aucun système
n'a profité du fait que BabelNet soit un inventaire multilingue ni que les
données de tests étaient parallèles. Néanmoins, les organisateurs ont remarqué
qu'en ne validant que les sens qui étaient les mêmes lorsque les mots étaient
alignés, la précision augmentait considérablement, ce qui est une piste à
explorer pour de futurs travaux.

\subsection{Modèles de langue pour la similarité sémantique}
\label{subsec:modeles_de_langue}

Une autre façon de représenter le sens des mots est possible grâce aux modèles
de langues. Un modèle de langue prédit la probabilité d'un mot étant donné son
contexte dans la phrase. Cette probabilité est directement utile pour des
tâches telles que la traduction automatique ou la reconnaissance de la parole
dans lesquelles un modèle de langue favorisera des phrases globalement
plausibles au lieu d'étudier chaque mot individuellement.

Ces modèles de langue permettent aussi d'obtenir des mesures de similarité
sémantiques utiles, ce qui est justifié par l'hypothèse distributionnelle
\cite[p.~156]{harris1954distributional} :

\begin{quote} ... si l'on considère que le sens de deux mots ou morphèmes A et B
    diffère davantage que le sens de A et C, alors on observe souvent que les
    distributions de A et B diffèrent davantage que les distributions de A et C.
    Autrement dit, la différence de sens est corrélée à la différence de
    distribution. \end{quote}

Cette observation est utilisée depuis longtemps pour étudier les similarités
sémantiques entre les mots à l'aide de matrices de co-occurrences
\citep{miller1967empirical}. Les modèles de langue sont une généralisation
permettant d'étudier ces distributions de probabilité. On peut étudier deux
types de distributions différentes correspondant à deux types de relations
entre les mots \citep{sahlgren2008distributional} :

\begin{itemize}
    \item les relations syntagmatiques identifient les mots qui sont présents
        ensemble dans un contexte donné ;
    \item les relations paradigmatiques identifient les mots qui sont présents
        dans un même contexte, mais sans y être présents ensemble.
\end{itemize}

Par exemple, étant donné les deux phrases \textit{Je bois du café} et \textit{Je
bois du thé}, on peut déduire que les lemmes \textit{boire} et \textit{thé} sont
liés par une relation syntagmatique : ils sont présents ensemble dans la
phrase. Au contraire, \textit{thé} et \textit{café} ne sont pas ici présents dans
la même phrase, mais apparaissent dans un même contexte (\textit{Je bois du}) :
ils sont liés par une relation paradigmatique.

Selon l'hypothèse distributionnelle faible \citep{lenci2008distributional},
observer les distributions de contexte des mots peut séparer les mots en
différents sens selon l'usage de chaque sens
\citep{yarowsky1993one,pantel2002discovering,pedersen2010duluth}. Cependant,
dans la littérature que nous exposons et dans nos travaux, les modèles de
langue ne décrivent que des mots en confondant leurs différents sens. Nous ne
mentionnerons plus par la suite cette difficulté, en considérant qu'il suffit
que le modèle de langue décrive parmi tous les sens celui que nous souhaitons
observer. Cette simplification est largement partagée par la littérature, même
si la disponibilité de corpus de plus d'un milliard de mots (\textit{gigaword})
rend possible des travaux prenant en compte la polysémie
\citep{kawahara2014step}.

Comment observer ces distributions de probabilité ? Un modèle de langue
classique indique la probabilité d'un mot dans une phrase étant donné les mots
précédents. Par exemple, étant donné le début de phrase \textit{Au-delà des
approches ...}, on veut connaître la probabilité du mot suivant, en espérant
que celle de \textit{statistiques} ou \textit{supervisées} soit plus importante que
celle de \textit{chat}. En prenant par exemple le contexte des deux mots qui
précèdent le mot étudié, on calcule sa probabilité simplement avec le maximum
de vraisemblance :

\[
p(w_i|w_{i-2}, w_{i-1}) = \frac{\#(w_{i-2}, w_{i-1}, w_i)}{\#(w_{i-1}, w_i)}
\]

La séquence $w_{i-2}, w_{i-1}, w_{i}$ est un 3-gramme, et $\#$ indique le
nombre d'occurrences de cette séquence dans le corpus considéré. La taille du
contexte peut varier, ce qui est la raison pour laquelle on parle de manière
générale de n-grammes. Le nombre de paramètres à estimer pour une distribution
de probabilité conditionnelle est $|V|^N$, $|V|$ étant la taille du vocabulaire
et $N$ la taille du contexte étudié. En considérant un petit vocabulaire
(10~000 mots) et un contexte de trois mots, il faut déjà estimer $10^{9}$
probabilités, ce qui requiert un corpus très large : Google a utilisé un corpus
de livres de $10^{12}$ mots pour produire des n-grammes allant jusqu'à $n=5$
\citep{brants2006web}. Diverses techniques de lissage existent pour mieux
répartir les probabilités obtenues par maximum de vraisemblance
\citep[Chapitre~4]{jurafsky2008speech}. En effet, la plupart des probabilités
sont initialement nulles, que ce soit parce que le n-gramme est
grammaticalement invalide ou simplement parce qu'il n'a pas été observé dans le
corpus étudié. Il faut alors estimer la probabilité de tels n-grammes à partir
d'un n-gramme plus court ou leur assigner une probabilité très faible pour
éviter les probabilités nulles.

\paragraph{Modèles de langues syntaxiques} Diverses extensions de ces modèles
de langues à base de n-grammes existent, l'une d'entre elles étant le modèle de
langue syntaxique \citep{lin1998automatic,goldberg2013dataset}. Dans ce modèle,
on considère les mots présents ensemble dans une relation syntaxique donnée.
Pour la relation complément du nom par exemple, on s'attend à ce que
\textit{vélo} soit le complément du nom des mots \textit{pédale},
\textit{guidon}, \textit{pneu}... Nous utilisons pour la traduction de WordNet
(Chapitre~\ref{ch:wonef}) un tel modèle de langue syntaxique
(\url{http://www.kalisteo.fr/demo/semanticmap/}).  Il a été entraîné sur un
corpus extrait du web francophone \citep{grefenstette2007conquering}. Le corpus
a ensuite été analysé par LIMA \citep{besancon2010lima}, une chaîne d'analyse
linguistique désormais libre utilisée ici comme un analyseur syntaxique à base
de règles produisant des dépendances syntaxiques fines. Pour une relation
donnée $r$ et un lemme $x$, le modèle de langue indique quels sont les 100
premiers lemmes co-occurrant le plus fréquemment avec $x$ dans la relation $r$.
Avec le mot \textit{avion} et la relation de complément du nom, c'est le mot
\textit{billet} qui modifie le plus \textit{avion} : \textit{billet d'avion}
est fréquent dans le corpus.


\tikzstyle{block}=[draw, fill=blue!5, rectangle, minimum height=0.5cm, minimum width=3cm, text width=5cm]

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[auto, node distance=2cm,>=latex']
    % Inspired from http://www.texample.net/tikz/examples/control-system-principles/
    \node [block, text width=10cm] (quillsynt1) {\Huge{billet}, \large{}pilote, vol, accident, \LARGE{détournement}, \large{}tour, \LARGE{collision}, \large{moteur}, \small{monde}, \LARGE{crash}, \large{}aile, bruit, \small{type}, \large{}carburant, attentat, \small{guerre}, \large{}chute, commande, \small{construction}, descente, \small{nombre}, \small{prix}, \small{achat}, \small{place}, \large{}réservation, passager, \small{programme}, \large{}bombe, \small{}peur, avion, \large{flotte}, \small{}transport \large{pilotage}, \LARGE{écrasement}, \small{}vitesse, utilisation, arrivée, \normalsize{}...};

  \end{tikzpicture}
  \caption{\textit{avion} est complément de ces noms d'après notre modèle de
  langue syntaxique. La taille des mots reflète la force de l'association.}
\end{figure}

\paragraph{Modèles de langues continus} D'autres types de modèles de langue
représentent les mots de manière distribuée en utilisant un vecteur de nombres
réels. LSA \citep{deerwester1990indexing}, par exemple, considère une matrice
de termes et de documents, les termes étant en ligne, les document en colonne.
Les éléments de cette matrice sont typiquement calculés avec TF-IDF. Cette
matrice est ensuite réduite, ce qui permet de généraliser en rapprochant la
similarité cosinus des mots qui apparaissent dans les mêmes documents. LSA fait
partie d'une classe de méthodes où on considère une matrice de co-occurrence
entre les mots et leurs contexte, une mesure d'association quelconque, une
factorisation potentielle, et une mesure de la distance entre les éléments,
l'objectif final étant de rapprocher les mots sémantiquement proches.

\paragraph{Modèles de langues neuronaux} Depuis la diffusion de word2vec
\citep{mikolov2013distributed} et de ses bons résultats obtenus dans un certain
nombre de tâches, l'utilisation de représentations de mots à l'aide de réseaux
de neurones est un champ actif de recherche\footnote{Les bons résultats obtenus
notamment en vision par ordinateur par des réseaux de neurones profonds ont
sûrement contribué à cet enthousiasme, il est donc important de rappeller que
les réseaux de neurones concernés ici ne sont pas profonds.}.  La manière la
plus répandue pour faire cela est d'utiliser un réseau de neurones peu profond
dont une des couches sera le vecteur représentant chaque mot.
\cite{hinton1986learning} a d'abord proposé l'idée d'un réseau de neurones pour
représenter des concepts à l'aide de vecteurs faisant partie du réseau,
\cite{bengio2001neural,bengio2003neural} ont présenté le modèle de langue
neuronal tel qu'on le connaît aujourd'hui, et \cite{mikolov2013distributed}
(parmi d'autres) a optimisé un modèle de langue en supprimant notamment une
couche cachée pour l'utiliser sur de plus gros corpus. Dans tous ces modèles,
lors de la rétropropagation du gradient, la représentation des mots évolue, ce
qui a pour effet de rapprocher la représentation des mots sémantiquement
proches afin d'offrir une meilleure généralisation, comme le fait LSA en
factorisant la matrice de co-occurrences.  Par exemple,
\cite{mikolov2013distributed} montrent que la distance entre le mot
représentant un pays (par exemple \textit{Turkey}) et le mot représentant la
capitale de ce pays (ici \textit{Ankara}) correspond au vecteur du mot
\textit{capital}.  Ces représentations de mots peuvent être ensuite utilisées ou
apprises pour diverses tâches. Nous citerons ici l'extraction d'évènements
\citep{boros2014etiquetage}, l'annotation en rôles sémantiques
\citep{lechelle2014utilisation} et la traduction automatique
\citep{devlin2014fast}, mais toute tâche peut bénéficier d'améliorations (plus
ou moins importantes) de telle représentations de mots où les mots
sémantiquement proches sont proches dans la représentation choisie.  Ces
réseaux de neurones sont encore difficiles à entraîner et à paramétrer
\citep{do2014modeles}, mais semblent représenter une alternative plus efficace
que les modèles de langue simples à base de n-grammes \citep{baroni2014dont}.

La compréhension des mécanismes derrières ces réseaux de neurones est un champ
actif de recherche. \cite{levy2014neural} ont montré que la méthode recommandée
par \cite{mikolov2013distributed} (\textit{negative sampling}) revient à
factoriser la matrice d'information mutuelle (légèrement modifiée) entre les
mots et les contextes en accordant plus d'importance aux termes fréquents, ce
qui est très proche des méthodes couramment utilisées en sémantique
distributionnelle et permet d'espérer une optimisation plus directe de
l'objectif afin d'améliorer les résultats tout en comprenant les méthodes
utilisées.

Bien que nous ne tirions pas profit des méthodes les plus récentes dans les
travaux que nous avons choisi de présenter ici, ces progrès importants sont à
considérer pour tout travail futur sur le sujet.

\section{Traductions de ressources linguistiques}
\label{sec:translation}

\subsection{WordNet}

WordNet (section~\ref{presentation_wordnet}) est une ressource extrêmement
utile pour l'anglais : reproduire ce travail pour d'autres langues serait
coûteux et difficile à maintenir. Malgré quelques problèmes théoriques,
traduire WordNet en gardant sa structure et ses synsets mène à des ressources
linguistiques utiles \citep{fellbaum2007connecting,demelo2008utility}.
Cependant, il n'existe encore que peu d'équivalents de même qualité dans
d'autres langues \citep{bond2012survey}, et il est donc utile de s'atteler à la
traduction de cette ressource.

Les traductions automatiques de WordNet emploient une approche dite d'extension
(\textit{expand approach}) : la structure de WordNet est préservée et seuls les
littéraux sont traduits. Trois techniques principales représentent cette
approche dans la littérature. La plus simple utilise des dictionnaires
bilingues pour faciliter le travail des lexicographes qui filtrent ensuite
manuellement les entrées proposées
\citep{vossen1998eurowordnet,pianta2002developing,tufis2004balkanet}. Une
deuxième méthode de traduction utilise des corpus parallèles, ce qui évite
l'utilisation de dictionnaires qui peuvent entraîner un biais lexicographique.
\cite{dyvik2004translations} représente cette méthode en s'appuyant sur des
\textit{back-translations} entre le norvégien et l'anglais, alors que
\citep{sagot2008construction} combinent un lexique multilingue et les
différents WordNets de BalkaNet comme autant de sources aidant à la
désambiguïsation. Troisièmement, plus récemment, des ressources telles que
Wikipédia ou le Wiktionnaire ont été explorées. Grâce aux nombreux liens entre
les différentes langues de ces ressources, il est possible de créer de nouveaux
wordnets
\citep{demelo2009towards,navigli2010babelnet,bond2013linking,aliabadi2014towards,oliver2014wn}
ou d'améliorer des wordnets existants \citep{hanoka2012wordnet}. Enfin,
\cite{fiser2014slowcrowd} montrent qu'il est possible de faire appel à la
production participative (\textit{crowdsourcing}).

Concernant le français, l'EuroWordNet \citep{vossen1998eurowordnet} est la
première traduction française de WordNet. C'est une ressource d'une couverture
limitée qui demande des améliorations significatives avant de pouvoir être
utilisée \citep{jacquin2006systemes}, et qui n'est ni libre ni librement
accessible. WOLF est une seconde traduction initialement construite à l'aide de
corpus parallèles \citep{sagot2008construction} et étendue depuis avec
différentes techniques \citep{apidianaki2012applying}. WOLF est distribué sous
une licence libre compatible avec la LGPL et c'est aujourd'hui le WordNet
français standard. JAWS \citep{mouton2010jaws} est une traduction des noms de
WordNet développée à l'aide de dictionnaires bilingues et d'un modèle de langue
syntaxique. Enfin, \cite{gader2014lexicon} montrent qu'il est possible de
convertir le Réseau Lexical du Français vers une représentation WordNet.


\label{subsec:jaws_translation_process}

Notre traduction de WordNet nommée WoNeF (Chapitre~\ref{ch:wonef}) est le
successeur de JAWS \citep{mouton2010jaws,mouton2010phd}. Cette section présente
JAWS. Le Chapitre~\ref{ch:wonef} liste lui seulement les différences avec JAWS
: il est donc nécessaire d'avoir compris le fonctionnement de JAWS avant de le
lire.

JAWS repose sur un algorithme faiblement supervisé qui ne demande aucune donnée
annotée manuellement. Pour traduire un wordnet source, JAWS s'appuie sur un
dictionnaire bilingue et un modèle de langue syntaxique pour la langue cible.
Le dictionnaire bilingue est une concaténation du dictionnaire bilingue
SCI-FRAN-EurADic\footnote{\url{http://catalog.elra.info/product_info.php?products_id=666}}
et des liens entre les Wiktionnaires français et
anglais\footnote{\url{http://www.wiktionary.org/}}. Le modèle de langue
syntaxique a été présenté à la section~\ref{subsec:modeles_de_langue}. Grâce
aux dictionnaires, JAWS n'a pas besoin de sélectionner les littéraux de chaque
synset parmi l'ensemble du vocabulaire mais seulement parmi un petit nombre de
candidats (9 en moyenne).  Le processus de traduction se fait en trois étapes :

\begin{enumerate}
    \item Créer un wordnet vide : la structure de WordNet est préservée, mais
        les synsets eux-mêmes n'ont pas de littéraux associés.
    \item Choisir les traductions les plus faciles parmi les candidats des
        dictionnaires pour commencer à remplir JAWS (sélecteurs initiaux).
    \item Étendre JAWS de manière incrémentale en utilisant le modèle de
        langue, les relations entre synsets et le JAWS déjà existant (autres
        sélecteurs).
\end{enumerate}

\label{jaws_extraction_heuristics}
\paragraph{Sélecteurs initiaux} Quatre algorithmes que nous nommons sélecteurs
initiaux choisissent des traductions correctes parmi celles qui sont proposées
par les dictionnaires.

\begin{itemize}

    \item Premièrement, les mots qui apparaissent dans un seul synset ne sont
        pas ambigus et il suffit d'ajouter toutes leurs traductions au WordNet
        français : c'est le sélecteur par monosémie. C'est le cas de
        \textit{grumpy} : toutes ses traductions sont validées dans le seul
        synset où il apparaît.

    \item Deuxièmement, le sélecteur par unicité identifie les mots n'ayant
        qu'une seule traduction et la valide dans tous les synsets où cette
        traduction est présente. Les cinq synsets contenant \textit{pill} en
        anglais sont ainsi complétés avec \textit{pilule}.

    \item Un troisième sélecteur vise à traduire les mots qui ne sont pas dans
        le dictionnaire en utilisant directement la traduction anglaise : c'est
        le sélecteur des transfuges.

    \item Un quatrième sélecteur utilise la distance d'édition de Levenshtein :
        si la distance entre un mot anglais et sa traduction est petite, on
        peut considérer que c'est le même sens (c'est le cas par exemple pour
        \textit{portion} ou encore \textit{university}), malgré l'existence de
        certains faux amis. Ces quatre sélecteurs produisent une première
        version du WordNet français qui contient assez de traductions pour
        pouvoir ensuite utiliser le modèle de langue et continuer de compléter
        les synsets.

\end{itemize}

\paragraph{Expansion de JAWS} JAWS étant partiellement rempli, une nouvelle étape d'expansion tire parti des relations entre les synsets de WordNet pour valider de nouvelles traductions. Par exemple, si :

\begin{itemize}

    \item un synset S1 est méronyme d'un synset S2 dans WordNet,

    \item dans notre modèle de langue, un littéral de S1 est méronyme d'un
        littéral candidat C dans S2,

\end{itemize}

alors ce littéral est considéré comme correct. La tâche de traduction est ainsi
réduite à une tâche de comparaison entre d'une part les relations lexicales
entre les synsets de WordNet et d'autre part les relations lexicales entre les
lexèmes du français.

Prenons l'exemple de \textit{quill} qui peut se traduire par \textit{piquant}
ou \textit{plume} (Figure \ref{meronymyexample}). Dans WordNet, \textit{quill}
est méronyme de \textit{porcupine} qui a déjà été traduit par
\textit{porc-épic} par un sélecteur initial. Dans le modèle de langue,
\textit{piquant} fait partie des compléments du nom de \textit{porc-épic} mais
ce n'est pas le cas de \textit{plume}. Ici, la relation de complément du nom
implique la méronymie et c'est donc \textit{piquant} qu'il faut choisir comme
la traduction correcte de \textit{quill}. Le modèle de langue a permis la
désambiguïsation parmi les deux traductions possibles.

\tikzstyle{block}=[draw, fill=blue!5, rectangle, minimum height=0.5cm, minimum
width=3cm, text width=5.1cm]

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}[auto, node distance=2cm,>=latex']
    % Inspired from http://www.texample.net/tikz/examples/control-system-principles/
    % first place and connect the outer blocks that represent synsets
      \node [block] (quill) {~\\\textbf{Synset S1} \\ - Anglais : quill \\ - Français : piquant? plume? \\ (a stiff hollow protective spine on a porcupine) \\ ~ };
      \node [block, text width=3.7cm, right of=quill, node distance=9cm] (porcupine) {\textbf{Synset S2} \\ - Anglais : porcupine, hedgehog \\ - Français : porc-épic \\ (rodents with sharp erectile bristles mingled with the fur)};
    \draw [<-] (porcupine) -- node[above] {méronyme de} (quill);
    \draw [<-] (porcupine) -- node[below] {(relation WordNet)} (quill);

    % then the syntactic model relations
    \node [block, below of=porcupine, text width=3.7cm, node distance=3cm] (porcupinesynt1) {porc-épic};
    \node [block, below of=quill, node distance=3cm] (quillsynt1) {\Large{mémoire}, \Large{piquant}, \large{poil}, \large{épine}, yéti, ragoût, grotte, \small{tactique}, \small{pelage}, \small{dextre}, \small{aiguille}, ...};
    \draw [<-] (porcupinesynt1) -- node[above] {complément du nom de} (quillsynt1);
    \draw [<-] (porcupinesynt1) -- node[below] {(modèle de langue)} (quillsynt1);

  \end{tikzpicture}
  \caption{\label{meronymyexample}Traduction via la relation de méronymie de partie.}
\end{figure}

Un problème potentiel avec cette approche est que la relation de complément du
nom n'est pas limitée à la méronymie. Par exemple, le mot \textit{mémoire} qui
est lui aussi associé à \textit{porc-épic} dans le modèle de langue vient d'un
livre intitulé \textit{Mémoires d'un porc-épic}. Heureusement, \textit{mémoire}
n'est pas dans les candidats de \textit{quill} et ne peut pas être choisi comme
une traduction. Paradoxalement, le modèle de langue ne peut pas choisir entre
deux mots très différents, mais est capable de faire le bon choix parmi les
différentes traductions d'un mot polysémique. Alors que traduire WordNet
automatiquement avec un dictionnaire ou un modèle de langue syntaxique est
impossible, combiner les deux sources d'information permet de résoudre le
problème.

Chaque sélecteur suit le même principe que le sélecteur par méronymie de partie
et traduit de nouveaux synsets en identifiant les relations entre lexèmes via
le modèle de langue syntaxique. La correspondance entre la relation de
complément du nom et la relation de méronymie est directe, mais ce n'est pas le
cas pour les autres relations : il n'y a par exemple pas de relation syntaxique
qui exprime directement la synonymie entre deux lexèmes. Pour ces relations, il
est nécessaire d'employer soit des motifs lexicaux \citep{hearst1992automatic}
soit des relations paradigmatiques \citep{lenci2012identifying}. Ce sont ces
dernières (section~\ref{subsec:modeles_de_langue}) que JAWS utilise. Pour la
synonymie, si deux mots partagent les mêmes co-occurrents dans une relation
syntaxique donnée, alors ils peuvent être synonymes dans ce contexte. Pour les
noms, les relations syntaxiques qui donnent les meilleurs résultats sont les
relations de complément du nom, d'objet du verbe et d'apposition. Concrètement,
si deux noms qui modifient les mêmes noms sont les objets des mêmes verbes ou
sont apposés aux mêmes noms, alors il est probable qu'ils soient synonymes et
si l'un des deux est déjà dans un synset, alors on peut y ajouter le second.
Par exemple, \textit{avant-propos} et \textit{préface} partagent les mêmes
compléments du noms : \textit{livre, édition, ouvrage}. Le sélecteur par
synonymie peut ajouter \textit{avant-propos} une fois que le littéral
\textit{préface} est dans JAWS. \citep{mouton2010jaws,mouton2010phd} décrivent
d'autres sélecteurs exploitant notamment les relations d'hyperonymie et
d'hyponymie.

\subsection{VerbNet}

Étant donné l'intérêt de la classification de verbes à la manière de VerbNet
\citep{hartshorne2014verbcorner} et l'intérêt de la ressource en Traitement
Automatique des Langues, VerbNet a été traduit ou recréé dans plusieurs
langues.

\paragraph{Acquisitions de VerbNets}

Premièrement, même si ce n'est pas dans le cadre d'une traduction de VerbNet,
un certain nombre de travaux cherchent à catégoriser automatiquement les verbes
en classes sémantiques, notamment pour l'espagnol \citep{ferrer2004towards},
l'allemand \citep{im2006experiments}, le japonais \citep{suzuki2009classifying}
et l'anglais
\citep{stevenson2003semi,lapata2004verb,vlachos2009unsupervised,lippincott2012learning,kawahara2014step},
où l'évaluation se fait notamment sur les classes de Levin. Pour l'anglais,
\citep{kawahara2014step} montrent qu'un corpus de plusieurs milliards de mot
permet de considérer la polysémie. En particulier, un corpus de 20 milliards de
mot améliore de manière conséquente l'état de l'art en considérant
l'affectation de verbes à plusieurs classes (71.39~\% de F1 contre 61.97~\%
pour LDA-frames \citep{materna2012lda}).

\paragraph{Traductions de VerbNet}

Concernant les traductions directes, \cite{merlo2002multilingual} ont utilisé
des similarités entres langues pour convertir 20 classes de Levin vers
l'Italien. Les seules traductions directes de VerbNet dont nous avons la
connaissance sont le VerbNet estonien \citep{jentson2014verbnet} et le VerbNet
portuguais brésilien \citep{scarton2012towards} (qui utilise des mappings entre
VerbNet et WordNet, et entre WordNet.Br et WordNet). \cite{scarton2014using}
proposent la création d'un VerbNet en s'appuyant comme seul effort manuel sur
la traduction manuelle des frames VerbNet vers la langue cible, puis de
ressources lexicales déjà disponibles (WordNet, VerbNet et WordNet traduit dans
la langue cible), le tout dans l'optique de créer des VerbNets pour les langues
proches de l'anglais disposant déjà d'un WordNet.  La méthode a été testée pour
le brésilien portuguais ; la comparaison des clusters de verbes de
\citep{scarton2012towards} indique un F-score de 60~\%.  Comme l'indiquent les
auteurs, même si l'effort pour créer un nouveau VerbNet est réduit, le lexique
obtenu a encore besoin d'être corrigée manuellement.

\paragraph{VerbNet en français}

Pour le français, \cite{saintdizier1996constructing} a produit une ressource
proche des classes de Levin dans l'objectif de s'en servir en Traitement
Automatique de Langues, tout comme VerbNet dix ans plus tard. Chacun des 1700
verbes est décrit par un certain nombre de «~contextes~» plus proches des
alternances de Levin que des frames VerbNet. Ces contextes proviennent de
différentes sources : les classes de Levin, les tables du Lexique-Grammaire, de
corpus et d'intuition linguistique. Cependant, l'effort sur cette ressource
s'est arrêté et le résultat n'est disponible que sur demande à l'auteur.

Des travaux se sont ensuite concentrés sur l'acquisition automatique de cadres
de sous-catégorisation et sur le regroupement de verbes en se basant sur ces
cadres et sur des similarités sémantiques. \cite{sun2010investigating} ont
utilisé un large lexique de cadres de sous-catégorisation
\citep{messiant2010acquisition} pour regrouper les verbes en clusters à l'aide
de traits sémantiques (colocations et préférences lexicales des verbes) et
syntaxiques (cadres de sous-catégorisation).  L'évaluation sur une
vérité-terrain créée manuellement a mené à une F-mesure de 55.1\%.
\cite{falk2012classifying} appliquent un algorithme de clustering différent et
utilisent des features différentes, ce qui améliore la F-mesure sur la même
vérité-terrain mais simplifiée, ce qui donne une F-mesure de 70\%.  Ces
ressources mettent en valeur de nouvelles façons de séparer les verbes du
Français, mais les erreurs qu'elles contiennent seront une nouvelle source
d'erreur dans les applications : il est important de les corriger si possible,
ce qui est la raison pour laquelle nous adoptons une approche différente qui
sera présentée au Chapitre~\ref{ch:verbnet}.

\subsection{FrameNet}
\label{traduction_framenet}

La théorie de FrameNet peut être utilisées dans d'autres domaines et d'autres
langues \citep{boas2009multilingual}. Il existe ainsi notamment des FrameNet en
espagnol \citep{subirats2003surprise}, japonais \citep{ohara2004japanese},
suédois \citep{heppin2012rocky} ou encore français avec le projet ANR ASFALDA
\citep{candito2014developing}. Certaines méthodes automatiques utilisent le
Wiktionnaire pour traduire le lexique FrameNet, mais pas son corpus
\citep{mouton2010framenet,hartmann2013framenet}, ce qui n'est pas directement
utile. Le Kicktionary \citep{schmidt2009kicktionary} est lui spécifique au
football et annote en trois langues (français, anglais, allemand) des dépêches
de presses de l'UEFA.  \cite{venturi2009towards} proposent un FrameNet italien
centré sur le domaine du droit. Enfin, il existe plusieurs FrameNets
spécialisés en portugais brésilien : un dans le domaine du droit
\citep{bertoldi2012frame} et l'autre pour la coupe du monde 2014
\citep{torrent2014copa}.

FrameNet est donc une ressource très riche qui peut s'adapter à de nombreux
domaines et à de nombreuses langues. Malheureusement, nous considérons que le
coût pour développer une telle ressource pour un nouveau domaine est prohibitif
et n'utilisons cette ressource que pour l'évaluation. Le projet FrameNet est
encore loin de couvrir un éventail complet du vocabulaire anglais
\citep[§5.4]{marquez2008semantic}, nécessitant de trouver d'autres moyens pour
étendre la ressource, notamment avec la myriadisation (\textit{crowdsourcing})
\citep{fossati2013outsourcing,baker2014framenet}.

\section{Annotation en rôles sémantiques}
\label{sec:srl}

Dans cette section, nous étudions les différentes façons de définir les rôles
sémantiques, examinons diverses ressources utiles pour la tâche d'annotation,
et présentons les techniques principales pour réaliser l'annotation elle-même.

\subsection{Les rôles sémantiques}
\label{subsec:roles_semantiques}

La notion de rôle sémantique semble particulièrement adaptée à notre volonté
d'aller au-delà de l'analyse syntaxique (section~\ref{au_dela}). Ces rôles ont
en effet pour objectif de s'abstraire des alternances de diathèse présentes
dans le langage naturel (Figure~\ref{fig:exemple_srl}).

\begin{figure}[ht]
    \centering
    \begin{tabular}{ccc}
        \toprule
        Carol & crushed   & the ice \\
        Agent & V         & Patient \\
        \midrule
        The ice & crushes & easily  \\
        Patient & V       &         \\
        \bottomrule
    \end{tabular}

    \caption{\label{fig:exemple_srl}Ces deux phrases annotées avec la classe
    VerbNet \texttt{carve-21.2} montrent que la position des arguments ne
détermine pas à elle seule les rôles sémantique. Ici, le sujet syntaxique est
tour à tour Agent (pour \textit{Carol}) puis Patient (pour \textit{The ice}).}
\end{figure}

\cite{fillmore1968case} a établi que le cas grammatical exhibe des relations
profondes et sémantiques. De nombreuses langues marquent ces relations au
niveau morphologique ; l'élatif est un exemple de cas grammatical qui exprime
le lieu de l'intérieur duquel provient un mouvement et qui est marqué
morphologiquement en finnois, hongrois et estonien. On peut alors, en se basant
sur ces informations linguistiques, définir un rôle sémantique pour ces cas
grammaticaux, même dans les langues où ils ne sont pas marqués
morphologiquement. La théorie des \textit{frame semantics}
\citep{fillmore1982frame} est une modification de la théorie des cas, et a
abouti à FrameNet où chaque situation ou \emph{frame} dispose de ses propres
rôles sémantiques, ce qui a créé plusieurs centaines de rôles. Ces rôles
partageant parfois le même nom, mais ce sont les liens entre les rôles qu'il
faut exploiter pour faire des généralisations \citep{litkowski2014framenet}

Il n'y a pas de réel consensus sur un inventaire de cas donnés. Parmi les rôles
sémantiques généralement acceptés \citep[p.~4]{palmer2010semantic}, on peut
citer :

\begin{itemize}
    \item l'\textbf{Agent} qui est à l'origine de l'action
    \item le \textbf{Patient} qui subit un changement d'état
    \item l'\textbf{Instrument} utilisé pour réaliser l'action
    \item le \textbf{Bénéficiaire} qui tire profit de l'action
\end{itemize}

Nous adoptons dans ce travail les rôles de notre lexique : VerbNet. Ce sont
21\footnote{Il y a 24 rôles en comptant Co-Agent, Co-Patient et Co-Theme.}
rôles supposés être suffisamment généraux pour s'adapter à toutes les
situations : \emph{Actor}, \emph{Agent}, \emph{Asset}, \emph{Attribute},
\emph{Beneficiary}, \emph{Cause}, \emph{Co-Agent}, \emph{Co-Patient},
\emph{Co-Theme}, \emph{Location}, \emph{Destination}, \emph{Source},
\emph{Experiencer}, \emph{Extent}, \emph{Instrument}, \emph{Material},
\emph{Product}, \emph{Patient}, \emph{Predicate}, \emph{Recipient},
\emph{Stimulus}, \emph{Theme}, \emph{Time} et \emph{Topic}.

\subsection{Lexiques et corpus}
\label{ressources_non_utilisees}

Il existe différentes ressources utiles dans le cadre de l'annotation en rôles
sémantique. Toutes les ressources que nous utilisons directement dans nos
travaux ont été présentées à la section~\ref{ressources_utilisees}.

\paragraph{PropBank}

PropBank \citep{palmer2005proposition} a décidé d'utiliser les annotations
syntaxiques du Penn TreeBank \citep{marcus1993building} pour annoter en rôles
sémantiques les phrases incluant un des 5000 verbes les plus fréquents du
corpus. Le principe est le même qu'avec les classes de Levin et VerbNet : la
syntaxe joue un rôle important pour la désambiguïsation des sens et
l'attribution des rôles sémantiques. Contrairement à VerbNet, PropBank se base
sur un corpus pour identifier les différentes constructions syntaxiques, les
sens des verbes et le sens à apporter aux rôles sémantiques. L'objectif
principal de PropBank est de permettre d'utiliser l'apprentissage automatique
pour l'annotation en rôles sémantiques. C'est pour cette raison que les
étiquettes disponibles sont très générales. Ainsi, il est fréquent que
\textit{ARG0} désigne l'agent, \textit{ARG1} le patient. D'autres arguments
sont disponibles pour étiqueter des rôles plus spécifiques (\textit{ARG2},
\textit{ARG3}, etc.) ainsi que des rôles secondaires (\textit{Location},
\textit{Extent}, \textit{Manner}, etc.)

\paragraph{NomBank}

NomBank \citep{meyers2004nombank} a été conçu à l'image de PropBank. La
spécificité de cette ressource est de se concentrer sur les noms communs, plus
particulièrement sur les 5~000 noms communs les plus fréquents dans le Penn
TreeBank. Sur le million de mots présent dans le corpus, 250 000 sont des noms
communs. 100 000 d'entre eux sont des noms issus d'un verbe ou qui se
comportent à la façon d'un verbe. Par exemple, le nom commun français « achat »
est lié au verbe « acheter », et les arguments sémantiques seront probablement
les mêmes : dans « Il a acheté un arbre » et « l'achat d'un arbre »,
\textit{ARG1} sera dans les deux cas l'arbre. D'autres catégories incluent les
noms partitifs, relationnels et environnementaux.

Pour une phrase telle que \textit{They gave the chefs a standing ovation}, les
annotations PropBank et NomBank proposent la même annotation, l'une étant basée
sur le groupe nominal (\textit{a standing ovation}), l'autre sur la structure
prédicat-argument autour du verbe \textit{gave}. Cette similarité volontaire a
permis de lier ces ressources
\citep{pustejovsky2005merging,verhagen2007combining}, mais nous ne connaissons
pas d'applications tirant profit de ces deux ressources.

\cite{gerber2010beyond} ont étendu NomBank aux arguments implicites, améliorant
ainsi la couverture de NomBank de 65\%, c'est-à-dire en augmentant le nombre
moyen de rôles remplis dans chaque exemple annoté. Il n'est pas rare que les
arguments soient implicites mais présents dans d'autres phrases. En effet, les
annotations étant volontairement limitées à la phrase, il n'est pas possible de
référer à un argument présent dans une phrase précédente.

Enfin, PropBank lui-même a récemment décidé d'inclure d'autres parties du
discours impliquant potentiellement des structures prédicat-argument en
s'inspirant notamment de NomBank : les noms, les adjectifs, et les verbes
support \citep{bonial2014propbank}.


\paragraph{Groningen Meaning Bank (GMB)}

Ce projet \citep{basile2014developing} vise à fournir un large corpus annoté de
l'anglais avec un nombre important de couches, le but étant de fournir un grand
corpus pour la recherche en «~sémantique~». Sont notamment inclus parmi les
couches : les lemmes, les parties du discours, la syntaxe (avec CCG). Il y a
aussi les sens WordNet, les rôles thématiques VerbNet, des annotations
sémantiques avec la DRT et des relations discours avec SDRT. C'est un corpus
prometteur qui unifie un nombre important d'annotations complémentaires et
jusque-là distinctes.

L'annotation des rôles VerbNet est effectuée directement au niveau de la
syntaxe, CCG donnant un moyen élégant d'associer les rôles au token prédicat
\citep{bos2012annotating}. Quelques difficultés conséquentes subsistent avant
de pouvoir s'en servir comme d'un corpus VerbNet:

\begin{itemize}
    \item Les classes VerbNet ne sont pas explicitement annotées, il faut les
        retrouver à travers le sens WordNet.
    \item Les frames VerbNet ne sont pas explicitement annotées, il faut les
        reconstruire d'après les supertags CCG.
    \item Il n'y a aucune garantie de cohérence avec VerbNet : si une frame est
        manquante ou erronée dans VerbNet, les annotateurs utilisent le mode
        \textit{open} et peuvent choisir n'importe quel rôle VerbNet.
\end{itemize}

\paragraph{Abstract Meaning Representation Bank (AMR Bank)}

Ce projet \citep{banarescu2013abstract} est un autre corpus à visée sémantique
pour l'anglais. Sa particularité est qu'il propose une forme d'interlingue
permettant d'annoter sémantiquement des corpus parallèles. Les rôles
sémantiques sont ceux de PropBank, ce qui permet d'envisager de s'en servir en
tant que corpus VerbNet.

\subsection{Approches d'annotation}

Les systèmes d'annotation en rôles sémantiques utilisent deux types de
ressources :

\begin{enumerate}
    \item Les \textbf{inventaires} examinés aux
        sections~\ref{ressources_utilisees} et \ref{ressources_non_utilisees}
        permettent de fournir un socle commun à différents systèmes. Ce sera
        par exemple la définition des frames, des rôles, des cadre de
        sous-catégorisation et des prédicats possibles.
    \item Les \textbf{corpus annotés} par des humains utilisent un inventaire
        donné pour réaliser la tâche qu'on essaie de faire apprendre aux
        systèmes. FrameNet contient de nombreux exemples annotés en plus des
        rôles sémantiques définis pour chacune des situations.
\end{enumerate}

Ces ressources sont utilisées différemment suivant les méthodes, souvent
divisées en trois approches générales : supervisées, fondées sur la
connaissance et non supervisées.

\paragraph{Supervisées}

Les méthodes supervisées
\citep{gildea2002automatic,surdeanu2008conll,das2014frame,hermann2014semantic,lluis2014shortest}
utilisent un corpus annoté, et adoptent donc l'inventaire associé. Des
techniques classiques d'apprentissage automatique sont utilisées pour
déterminer le sens correct de chaque occurrence d'un mot étant donné les
informations obtenues à partir du contexte de cette occurrence.  L'annotation
en rôles sémantiques supervisée est souvent divisée en plusieurs sous-tâches,
parfois partiellement regroupées :

\begin{itemize}
    \item l'identification des prédicats,
    \item l'identification des frames,
    \item l'identification des arguments qui établit les syntagmes jouant un rôle dans la phrase,
    \item et la classification des rôles qui détermine le rôle effectif de
chaque syntagme parmi ceux retenus à la phase précédente.
\end{itemize}

Nous ne rentrons pas ici dans le détail des techniques utilisées par les
méthodes supervisées. Elles s'adaptent en général efficacement à leur corpus
annoté et possèdent donc les meilleurs résultats sur ces corpus, mais d'autres
techniques sont souhaitables pour généraliser à d'autres domaines non couverts
par ces corpus annotés.

% Si on voulait faire un état de l'art, on pourrait citer des méthodes basées
% sur des word reprs: lechelle2014, kanerva2014, roth2014composition

\paragraph{Fondées sur la connaissance}

Quelques approchent n'utilisent pas de corpus annoté mais se content de la
ressource VerbNet
\citep{swier2004unsupervised,swier2005exploiting,pradet2013revisiting}. Les
systèmes s'affranchissent alors de la petite taille inhérente à tout corpus
annoté et s'appuient sur les cadres de sous-catégorisation pour l'annotation.
Un inventaire de sens est utilisé : il faut toujours aussi faire de la
classification ; la difficulté principale étant ici d'obtenir des informations
utiles sans exemples annotés. Étant donné que ces méthodes continuent à
utiliser un inventaire, il reste possible de comparer les résultats entre
différents systèmes et de réaliser une évaluation sur une vérité-terrain. C'est
l'approche pour laquelle nous optons ici : nos apports sont décrits au
chapitre~\ref{ch:srl}.

\paragraph{Semi-supervisées}

\cite{vanderplas2014cross} annotent le corpus Europarl anglais avec un système
automatique entrainé sur PropBank, puis utilisent les alignements du corpus
pour obtenir un corpus français automatiquement annoté en rôles PropBank. C'est
une piste intéressante pour obtenir des corpus annotés en rôles sémantiques
pour le français. Diverses difficultés restent : les données PropBank anglaises
ont été directement utilisées pour le français, et les scores encore trop
faibles nécessitent une correction manuelle du corpus. De manière similaire,
\cite{exner2014using} proposent de développer automatiquement un nouveau
PropBank du suédois en se basant sur le PropBank anglais et en utilisant
Wikipédia comme un corpus parallèle. La précision des données obtenues est
encore inconnue.

% LATER pado2006optimal, furstenau2012semi, titov2013crosslingual

D'autres méthodes transfèrent directement les modèles appris d'une langue vers
d'autres. \citep{zeman2008cross} appliquent un modèle appris sur un corpus
danois et l'appliquent à un corpus suédois, et montrent qu'il faut un corpus de
1500 phrases annotées en suédois pour qu'un modèle entraîné directement sur le
corpus suédois soit meilleur que leur système. \citep{kozhevnikov2013cross}
montrent sur trois paires de langues (Anglais-Chinois, Anglais-Tchèque et
Anglais-Français) que les résultats sont meilleurs en modifiant le modèle
appris qu'en projetant l'annotation comme au paragraphe précédent.

\paragraph{Non supervisées}

Ces approches n'utilisent aucune connaissance \textit{a priori}, que ce soit un
inventaire ou un corpus annoté. Une approche non supervisée doit nécessairement
construire son propre inventaire. Cette construction peut se faire via du
\textit{clustering} de sens à partir des occurrences de contextes trouvées dans
le corpus
\citep{lang2011unsupervised,garg2012unsupervised,titov2012bayesian,materna2013parameter}.

Les avantages potentiels sont nombreux. Ces algorithmes ne nécessitent aucune
ressource, et offrent de fait deux propriétés intéressantes :

\begin{itemize}

    \item L'inventaire choisi colle au plus près du corpus utilisé, ce qui lui
        permet à la fois d'éviter des distinctions trop fines et de s'adapter à
        de nouveaux domaines via de nouveaux corpus, le domaine ayant un impact
        important sur les sens utilisés.

    \item Plus la quantité de texte disponible augmente, plus le système peut
        devenir efficace.

\end{itemize}

Malheureusement, les systèmes utilisant une approche non supervisée sont
difficiles à évaluer et à utiliser directement dans des systèmes plus
importants. Par exemple, dans le cadre de la traduction automatique, distinguer
les sens ne suffit pas ; il faut aussi savoir quelle traduction appliquer.
Ainsi, bien que représentant une voie prometteuse, nous n'avons pas considéré
ici ce type de méthode.

\subsection{Terminologie}

En français, le terme «~annotation en rôles sémantiques~» n'est pas encore
stabilisé. En effet, de nombreux termes coexistent encore aujourd'hui :

\begin{itemize}
    \item \textit{Annotation syntaxico-sémantique des actants}
        \citep{hadouche2011annotation},
    \item \textit{étiquetage en rôles sémantiques} \citep{boros2014etiquetage},
    \item \textit{étiquetage de rôles sémantiques}
        \citep{lechelle2014utilisation},
    \item ou encore \textit{prédiction de la structure sémantique}
        \citep{michalon2014modelisation}.
\end{itemize}

Tous ces travaux traitent de ressources proches de FrameNet. Ce n'est pas le
cas en anglais, où la littérature utilise aujourd'hui deux termes différents
pour distinguer l'annotation en rôles sémantiques de type PropBank
(\textit{Semantic Role Labeling}) et l'annotation en rôles sémantiques de type
FrameNet (\textit{Frame-semantic parsing}). En effet, ce sont deux tâches
relativement différentes.

\begin{itemize}
    \item Pour PropBank, il s'agit d'identifier les arguments de chaque sens de
        verbe (ARG0, ARG1, etc.) sans avoir besoin de deśambiguïser le sens du
        verbe \citep{carreras2005introduction}.
    \item Pour FrameNet, il faut identifier les prédicats (verbes mais aussi
        noms, adjectifs et adverbes), identifier la frame correspondante (tâche
        proche de la désambiguïsation lexicale), et ensuite, à la manière de
        PropBank, identifier les arguments et leurs rôles sémantiques. Pour
        montrer la différence avec le \textit{semantic role labeling}, le terme
        \textit{frame-semantic parsing} a été choisi
        \citep{das2010probabilistic}.
\end{itemize}

Dans ce sens, nos travaux sont effectivement du \textit{frame-semantic
parsing}, même si nous ne traitons que des verbes. En effet, la
désambiguïsation entre classes VerbNet joue un rôle important dans notre
système (Chapitre~\ref{ch:srl}).


\subsection{Adaptation au domaine}

\cite{chen2008learning} entraînent un système qui apprend à commenter un match
de football en utilisant des commentaires existants et des simulations de jeux
de football, mais sans connaissance explicite sur la langue anglaise.  Leur
approche a entraîné des travaux sur le \textit{situated language understanding}
(compréhension ancrée du langage):
\cite{bordes2010towards,richardson2012towards} ont proposé par la suite
d'autres corpus pour cette tâche. \cite{chang2014learning} génèrent eux des
scènes 3D à partir de textes tels que "Il y a une pièce avec une chaise et un
ordinateur" en essayant d'inférer les contraintes implicites telles que la
présence d'un bureau. Notre système (Chapitre~\ref{ch:domainsrl}) est similaire
à ces systèmes dans le sens où nous minimisons l'effort humain pour annoter de
nouveaux domaines, mais nous nous concentrons sur l'annotation en rôles
sémantiques \textit{à la FrameNet}.

Le système d'annotation en rôles sémantiques de \cite{gormley2014low} n'a pas
besoin de corpus annoté en syntaxe, mais nécessite un corpus annoté en rôles
sémantiques. \cite{hadouche2011annotation} effectue une annotation en rôles
sémantiques sur le corpus DicoInfo \citep{corpusolst} à l'aide de deux
approches :

\begin{itemize}
    \item en appliquant des règles définies manuellement s'appliquant à la
        sortie d'un analyseur syntaxique,
    \item en apprenant un système supervisé en utilisant divers traits issus de
        la littérature.
\end{itemize}

Même si nous utilisons le même corpus, nos travaux vont dans la direction
opposée : nous souhaitons annoter un grand nombre de phrases provenant de
divers domaines sans utiliser de corpus annoté.

Ce travail conclut en indiquant que pour obtenir de meilleurs résultats sur
plus de rôles et de prédicats, il faut plus d'exemples d'entraînement. Notre
travail prend une autre direction : nous étudions l'utilisation de moins de
données créées manuellement pour couvrir plus de phrases dans divers domaines.

En conclusion, les approches pour annoter un texte en rôles sémantiques sont
nombreuses mais les difficultés restant à franchir pour annoter un texte
français en cadre ouvert restent nombreuses. La partie suivante décrit les
efforts réalisés pour adapter au français des ressources qui ont prouvé leur
utilité en anglais.
